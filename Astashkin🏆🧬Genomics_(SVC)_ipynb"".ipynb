{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Artemiy2708/ML/blob/main/Astashkin%F0%9F%8F%86%F0%9F%A7%ACGenomics_(SVC)_ipynb%22%22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbiR4YHvyX1f"
      },
      "source": [
        "<small><font color=gray>Notebook author: <a href=\"https://www.linkedin.com/in/olegmelnikov/\" target=\"_blank\">Oleg Melnikov</a>, ¬©<a href=\"https://apps.ep.jhu.edu/course-homepages/3765-605-742-deep-neural-networks\" target=\"_blank\">JHU</a> 2021 onwards</font></small><hr style=\"margin:0;background-color:silver\">\n",
        "\n",
        "# **[üèÜüß¨Genomics](https://www.kaggle.com/c/3722genomics/rules)**\n",
        "\n",
        "See [**instructions**](https://colab.research.google.com/drive/1riOGrE_Fv-yfIbM5V4pgJx4DWcd92cZr#scrollTo=ITaPDPIQEgXV) for running and naming your Colab notebooks."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(Optioal) CONSENT.** If ok with sharing your Colab for educational purposes, please check the box below with \"X\".\n",
        "\n",
        "<mark>[ . . ]</mark> We consent to sharing our Colab (after the assignment ends) with other students/instructors for educational purpose. We understand that sharing is optional and this decision will not affect our grade in any way. "
      ],
      "metadata": {
        "id": "mwuPxmU5NFLz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " from google.colab import drive; drive.mount('/content/drive')   # OK to enable, if your kaggle.json is stored in Google Drive"
      ],
      "metadata": {
        "id": "4ZK9-jiByA4Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a3336b0-5624-494a-e8f4-479b63aeb5b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install --upgrade --force-reinstall --no-deps kaggle > log  # upgrade kaggle package (to avoid a warning)\n",
        "!mkdir -p ~/.kaggle                               # .kaggle folder must contain kaggle.json for kaggle executable to properly authenticate you to Kaggle.com\n",
        "!cp /content/drive/MyDrive/kaggle/kaggle.json ~/.kaggle/kaggle.json >log  # First, download kaggle.json from kaggle.com (in Account page) and place it in the root of mounted Google Drive\n",
        "!cp kaggle.json ~/.kaggle/kaggle.json > log       # Alternative location of kaggle.json (without a connection to Google Drive)\n",
        "!chmod 600 ~/.kaggle/kaggle.json                  # give only the owner full read/write access to kaggle.json\n",
        "!kaggle config set -n competition -v 3722genomics # set the competition context for the next few kaggle API calls. !kaggle config view - shows current settings\n",
        "!kaggle competitions download >> log              # download competition dataset as a zip file\n",
        "!unzip -o *.zip >> log                          # Kaggle dataset is copied as a single file and needs to be unzipped.\n",
        "!pip install -U sentence-transformers\n",
        "# !kaggle competitions leaderboard --show           # print public leaderboard "
      ],
      "metadata": {
        "id": "dt1AeSYEx5kV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26f472cb-780b-4565-a382-f450f0d123ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat '/content/drive/MyDrive/kaggle/kaggle.json': No such file or directory\n",
            "cp: cannot stat 'kaggle.json': No such file or directory\n",
            "- competition is now set to: 3722genomics\n",
            "100% 9.65M/9.65M [00:01<00:00, 6.93MB/s]\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.7/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.7.3)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.13.1+cu113)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.11.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.12.1+cu113)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.0.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.7)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.1.97)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.24.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.64.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.13.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.1.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (3.0.9)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.6.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface-hub>=0.4.0->sentence-transformers) (3.10.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "%%capture\n",
        "%reset -f\n",
        "!pip -q install -U sentence-transformers > log\n",
        "from IPython.core.interactiveshell import InteractiveShell as IS; IS.ast_node_interactivity = \"all\" \n",
        "import numpy as np, pandas as pd, time, matplotlib.pyplot as plt, os, plotly\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sentence_transformers import SentenceTransformer as SBERT\n",
        "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
        "ToCSV = lambda df, fname: df.round(2).to_csv(f'{fname}.csv', index_label='id') # rounds values to 2 decimals\n",
        "\n",
        "class Timer():\n",
        "  def __init__(self, lim:'RunTimeLimit'=60*5): self.t0, self.lim, _ = time.time(), lim, print(f'‚è≥ started. You have {lim} sec. Good luck!')\n",
        "  def ShowTime(self):\n",
        "    msg = f'Runtime is {time.time()-self.t0:.0f} sec'\n",
        "    print(f'\\033[91m\\033[1m' + msg + f' > {self.lim} sec limit!!!\\033[0m' if (time.time()-self.t0-1) > self.lim else msg)\n",
        "\n",
        "np.set_printoptions(linewidth=10000, precision=4, edgeitems=20, suppress=True)\n",
        "pd.set_option('max_rows', 100, 'max_columns', 100, 'max_colwidth', 100, 'precision', 2, 'display.max_rows', 4)"
      ],
      "metadata": {
        "id": "yGUK_EcvtN8y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cb5f2f6-bb42-4dc2-9897-9570ba690af5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 498 ms, sys: 23.1 ms, total: 521 ms\n",
            "Wall time: 5 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1TC9f43ItUY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "outputId": "f5cb2ad4-8574-42c5-a970-0e134e488a3c"
      },
      "source": [
        "vX = pd.read_csv('testX/testX.csv').set_index('id')\n",
        "tYX = pd.read_csv('trainYX/trainYX.csv').set_index('id')\n",
        "vX"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                        DNA\n",
              "id                                                                                                         \n",
              "100000  TTGATTAATAAGATTCCTTGACACCCTTTGTAAAGTTTCTATTTCGTGTGAAATATCTATCTCTTCAAATCCTTTTAATTTATCTAGGTATTTGCT...\n",
              "100001  ATTAGTAACGGAGGATTTACTAGATGTTTGGATTTATATTCTAATTTTATTCAGGTGGAAGGGATTGTTTTATGATTCAATAGTATACAGAGAATA...\n",
              "...                                                                                                     ...\n",
              "119998  CGTCGGCATGCTCGGGCAGTGCGGCGGGCCAGCAGCGTGCCAGTTGTCGCGGGGCGGCCGGGCATCGCGGCGCCGGGCGGCAGCACTCCCGCGAAG...\n",
              "119999  GCGAGGGCACGAAGGCACGACGGCAACGGCGGCGAGGAGCGCTGTGGCAACCGTCTCCGCGTTTGCGTGCGTACAGCCGAGAGCTGGTTCGCGCAG...\n",
              "\n",
              "[20000 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d1223104-3e38-4dab-b0e7-488eeafa1627\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DNA</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>100000</th>\n",
              "      <td>TTGATTAATAAGATTCCTTGACACCCTTTGTAAAGTTTCTATTTCGTGTGAAATATCTATCTCTTCAAATCCTTTTAATTTATCTAGGTATTTGCT...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100001</th>\n",
              "      <td>ATTAGTAACGGAGGATTTACTAGATGTTTGGATTTATATTCTAATTTTATTCAGGTGGAAGGGATTGTTTTATGATTCAATAGTATACAGAGAATA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119998</th>\n",
              "      <td>CGTCGGCATGCTCGGGCAGTGCGGCGGGCCAGCAGCGTGCCAGTTGTCGCGGGGCGGCCGGGCATCGCGGCGCCGGGCGGCAGCACTCCCGCGAAG...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119999</th>\n",
              "      <td>GCGAGGGCACGAAGGCACGACGGCAACGGCGGCGAGGAGCGCTGTGGCAACCGTCTCCGCGTTTGCGTGCGTACAGCCGAGAGCTGGTTCGCGCAG...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20000 rows √ó 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d1223104-3e38-4dab-b0e7-488eeafa1627')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d1223104-3e38-4dab-b0e7-488eeafa1627 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d1223104-3e38-4dab-b0e7-488eeafa1627');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JVbzlnuIud4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c623b027-45c2-4590-8dad-701c30ab0f28"
      },
      "source": [
        "tmr = Timer() # runtime limit (in seconds). Add all of your code after the timer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚è≥ started. You have 300 sec. Good luck!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLxefmk0Iz0U"
      },
      "source": [
        "‚ùóDo not modify the setup above."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr color=red>\n",
        "\n",
        "<font size=5>‚è≥</font> <strong><font color=orange size=5>Your Code, Documentation, Ideas and Timer - All Start Here...</font></strong>\n",
        "\n",
        "**Student's Section** (between ‚è≥ symbols): add your code and documentation here."
      ],
      "metadata": {
        "id": "3NcTKbw3KhAn"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpyLNt3god0c"
      },
      "source": [
        "## **Task 1. Preprocessing Pipeline**\n",
        " \n",
        "Explain elements of your preprocessing pipeline i.e. feature engineering, subsampling, clustering, dimensionality reduction, etc. \n",
        "1. Why did you choose these elements? (Something in EDA, prior experience,...? Btw, EDA is not required)\n",
        "1. How do you evaluate the effectiveness of these elements? \n",
        "1. What else have you tried that worked or didn't? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30xYIFXAnaPE"
      },
      "source": [
        "**Student's answer:**\n",
        "We changed transformer for the best one in the SBERT package(highest average score). Also, we tried Standard Scaling, PCA , but PCA did not work, Standart scaler we did not have submissions left, to submit the same model with Scaled data. Apart from that we did not do anything else as the score accuracy was high enough, so we did not try to additional eda, and data preproccesing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGJRwzqHob4o"
      },
      "source": [
        "## **Task 2. Modeling Approach**\n",
        "Explain your modeling approach, i.e. ideas you tried and why you thought they would be helpful. \n",
        "\n",
        "1. How did these decisions guide you in modeling?\n",
        "1. How do you evaluate the effectiveness of these elements? \n",
        "1. What else have you tried that worked or didn't? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zi6ZjgtWnb58"
      },
      "source": [
        "**Student's answer:**\n",
        "We tried Linear SVC, and SVC (linear, rbf, polynomial with degree 2 and 3). Used Grid Search to find optimal C in linear SVC and for all other types also. c=100 showed the best performance on linear,having 0,98 on Public LB, rbf was less ( 0.9730 ), the polynomial c-=100, gamma=0.1, .svm.Svc(linear) has 0.9797 on c=10, gamma=1, it is strange that it differs by optimal parametres from LinearSvc, and score is close, but still less. Polynomial degree=3, gamma=0.1, C=0.1 gave the highest performace from all poly on cross validation, but still less on kaggle- 0,9789.So, we choose Linear SVC with c=100 as the best model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-w7CLJeJAZC"
      },
      "source": [
        "[SBERT](https://www.sbert.net) generates 384-dimensional text embedding vectors for each text entry. See [more models](https://www.sbert.net/docs/pretrained_models.html).\n",
        "* Only reputable publicly available embedding models are allowed (SBERT, USE, MUSE, LASER, ...). We want to prevent participants' training embeddings on test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfkARvtJJCum"
      },
      "source": [
        "%%capture\n",
        "# sbert = SBERT('paraphrase-MiniLM-L6-v2')  # 4 seconds; loads SBERT embeddings model\n",
        "\n",
        "sbert = SBERT('paraphrase-multilingual-mpnet-base-v2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_586zfPPJD4C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "9ad79e5d-60b1-47ce-c682-5525efa37cfe"
      },
      "source": [
        "tYX = tYX.head(10000)\n",
        "tEmb, vEmb = sbert.encode([s[:200] for s in tYX.DNA]), sbert.encode([s[:200] for s in vX.DNA])  # embed all sequences to same-size vectors\n",
        "print(f'Train embedding matrix size:', tEmb.shape)\n",
        "pd.DataFrame(vEmb[:3,:30], index=[x[:20]+'...' for x in vX.DNA[:3]]).style.background_gradient(cmap='coolwarm', axis=1).set_precision(2)  # show movie description and a few of its embedding features"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train embedding matrix size: (10000, 768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: this method is deprecated in favour of `Styler.format(precision=..)`\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7fcaf797fa50>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_8e03d_row0_col0 {\n",
              "  background-color: #a2c1ff;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_8e03d_row0_col1, #T_8e03d_row1_col1, #T_8e03d_row2_col1 {\n",
              "  background-color: #b40426;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_8e03d_row0_col2, #T_8e03d_row1_col3, #T_8e03d_row2_col7 {\n",
              "  background-color: #afcafc;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_8e03d_row0_col3 {\n",
              "  background-color: #f7ba9f;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_8e03d_row0_col4 {\n",
              "  background-color: #f7a889;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_8e03d_row0_col5 {\n",
              "  background-color: #d24b40;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_8e03d_row0_col6, #T_8e03d_row1_col26 {\n",
              "  background-color: #a1c0ff;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_8e03d_row0_col7, #T_8e03d_row1_col6 {\n",
              "  background-color: #e7d7ce;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_8e03d_row0_col8 {\n",
              "  background-color: #a6c4fe;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_8e03d_row0_col9 {\n",
              "  background-color: #c32e31;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_8e03d_row0_col10 {\n",
              "  background-color: #d85646;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_8e03d_row0_col11 {\n",
              "  background-color: #f4987a;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_8e03d_row0_col12 {\n",
              "  background-color: #edd2c3;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_8e03d_row0_col13 {\n",
              "  background-color: #da5a49;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_8e03d_row0_col14 {\n",
              "  background-color: #cad8ef;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_8e03d_row0_col15, #T_8e03d_row1_col15, #T_8e03d_row2_col15 {\n",
              "  background-color: #3b4cc0;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_8e03d_row0_col16, #T_8e03d_row2_col0 {\n",
              "  background-color: #9fbfff;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_8e03d_row0_col17 {\n",
              "  background-color: #ec8165;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_8e03d_row0_col18 {\n",
              "  background-color: #c3d5f4;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_8e03d_row0_col19 {\n",
              "  background-color: #ec7f63;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_8e03d_row0_col20 {\n",
              "  background-color: #f5c4ac;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_8e03d_row0_col21 {\n",
              "  background-color: #b7cff9;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_8e03d_row0_col22, #T_8e03d_row0_col26 {\n",
              "  background-color: #f6a283;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_8e03d_row0_col23 {\n",
              "  background-color: #9bbcff;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_8e03d_row0_col24, #T_8e03d_row2_col25 {\n",
              "  background-color: #7597f6;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_8e03d_row0_col25 {\n",
              "  background-color: #9abbff;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_8e03d_row0_col27 {\n",
              "  background-color: #cedaeb;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_8e03d_row0_col28, #T_8e03d_row1_col13 {\n",
              "  background-color: #efcfbf;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_8e03d_row0_col29 {\n",
              "  background-color: #8db0fe;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_8e03d_row1_col0 {\n",
              "  background-color: #7295f4;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_8e03d_row1_col2, #T_8e03d_row1_col7, #T_8e03d_row1_col29 {\n",
              "  background-color: #688aef;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_8e03d_row1_col4, #T_8e03d_row2_col16 {\n",
              "  background-color: #8fb1fe;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_8e03d_row1_col5 {\n",
              "  background-color: #cbd8ee;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_8e03d_row1_col8 {\n",
              "  background-color: #a7c5fe;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_8e03d_row1_col9 {\n",
              "  background-color: #dfdbd9;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_8e03d_row1_col10 {\n",
              "  background-color: #f7a98b;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_8e03d_row1_col11 {\n",
              "  background-color: #aac7fd;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_8e03d_row1_col12 {\n",
              "  background-color: #9dbdff;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_8e03d_row1_col14, #T_8e03d_row1_col25 {\n",
              "  background-color: #6e90f2;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_8e03d_row1_col16 {\n",
              "  background-color: #a5c3fe;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_8e03d_row1_col17 {\n",
              "  background-color: #b6cefa;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_8e03d_row1_col18 {\n",
              "  background-color: #3e51c5;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_8e03d_row1_col19 {\n",
              "  background-color: #e5d8d1;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_8e03d_row1_col20, #T_8e03d_row1_col22 {\n",
              "  background-color: #c5d6f2;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_8e03d_row1_col21, #T_8e03d_row1_col24 {\n",
              "  background-color: #5b7ae5;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_8e03d_row1_col23 {\n",
              "  background-color: #6b8df0;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_8e03d_row1_col27 {\n",
              "  background-color: #7396f5;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_8e03d_row1_col28 {\n",
              "  background-color: #e9d5cb;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_8e03d_row2_col2 {\n",
              "  background-color: #9ebeff;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_8e03d_row2_col3 {\n",
              "  background-color: #d8dce2;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_8e03d_row2_col4 {\n",
              "  background-color: #f39475;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_8e03d_row2_col5 {\n",
              "  background-color: #ea7b60;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_8e03d_row2_col6 {\n",
              "  background-color: #7a9df8;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_8e03d_row2_col8 {\n",
              "  background-color: #abc8fd;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_8e03d_row2_col9 {\n",
              "  background-color: #dc5d4a;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_8e03d_row2_col10 {\n",
              "  background-color: #c73635;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_8e03d_row2_col11 {\n",
              "  background-color: #d1dae9;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_8e03d_row2_col12 {\n",
              "  background-color: #e3d9d3;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_8e03d_row2_col13 {\n",
              "  background-color: #f7ac8e;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_8e03d_row2_col14 {\n",
              "  background-color: #d6dce4;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_8e03d_row2_col17 {\n",
              "  background-color: #f7af91;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_8e03d_row2_col18 {\n",
              "  background-color: #b1cbfc;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_8e03d_row2_col19 {\n",
              "  background-color: #f4c5ad;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_8e03d_row2_col20 {\n",
              "  background-color: #e8d6cc;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_8e03d_row2_col21 {\n",
              "  background-color: #adc9fd;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_8e03d_row2_col22, #T_8e03d_row2_col26 {\n",
              "  background-color: #f5c1a9;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_8e03d_row2_col23 {\n",
              "  background-color: #bad0f8;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_8e03d_row2_col24 {\n",
              "  background-color: #7699f6;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_8e03d_row2_col27 {\n",
              "  background-color: #c7d7f0;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_8e03d_row2_col28 {\n",
              "  background-color: #ead4c8;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_8e03d_row2_col29 {\n",
              "  background-color: #88abfd;\n",
              "  color: #000000;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_8e03d_\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th class=\"col_heading level0 col0\" >0</th>\n",
              "      <th class=\"col_heading level0 col1\" >1</th>\n",
              "      <th class=\"col_heading level0 col2\" >2</th>\n",
              "      <th class=\"col_heading level0 col3\" >3</th>\n",
              "      <th class=\"col_heading level0 col4\" >4</th>\n",
              "      <th class=\"col_heading level0 col5\" >5</th>\n",
              "      <th class=\"col_heading level0 col6\" >6</th>\n",
              "      <th class=\"col_heading level0 col7\" >7</th>\n",
              "      <th class=\"col_heading level0 col8\" >8</th>\n",
              "      <th class=\"col_heading level0 col9\" >9</th>\n",
              "      <th class=\"col_heading level0 col10\" >10</th>\n",
              "      <th class=\"col_heading level0 col11\" >11</th>\n",
              "      <th class=\"col_heading level0 col12\" >12</th>\n",
              "      <th class=\"col_heading level0 col13\" >13</th>\n",
              "      <th class=\"col_heading level0 col14\" >14</th>\n",
              "      <th class=\"col_heading level0 col15\" >15</th>\n",
              "      <th class=\"col_heading level0 col16\" >16</th>\n",
              "      <th class=\"col_heading level0 col17\" >17</th>\n",
              "      <th class=\"col_heading level0 col18\" >18</th>\n",
              "      <th class=\"col_heading level0 col19\" >19</th>\n",
              "      <th class=\"col_heading level0 col20\" >20</th>\n",
              "      <th class=\"col_heading level0 col21\" >21</th>\n",
              "      <th class=\"col_heading level0 col22\" >22</th>\n",
              "      <th class=\"col_heading level0 col23\" >23</th>\n",
              "      <th class=\"col_heading level0 col24\" >24</th>\n",
              "      <th class=\"col_heading level0 col25\" >25</th>\n",
              "      <th class=\"col_heading level0 col26\" >26</th>\n",
              "      <th class=\"col_heading level0 col27\" >27</th>\n",
              "      <th class=\"col_heading level0 col28\" >28</th>\n",
              "      <th class=\"col_heading level0 col29\" >29</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_8e03d_level0_row0\" class=\"row_heading level0 row0\" >TTGATTAATAAGATTCCTTG...</th>\n",
              "      <td id=\"T_8e03d_row0_col0\" class=\"data row0 col0\" >-0.03</td>\n",
              "      <td id=\"T_8e03d_row0_col1\" class=\"data row0 col1\" >0.11</td>\n",
              "      <td id=\"T_8e03d_row0_col2\" class=\"data row0 col2\" >-0.02</td>\n",
              "      <td id=\"T_8e03d_row0_col3\" class=\"data row0 col3\" >0.04</td>\n",
              "      <td id=\"T_8e03d_row0_col4\" class=\"data row0 col4\" >0.05</td>\n",
              "      <td id=\"T_8e03d_row0_col5\" class=\"data row0 col5\" >0.09</td>\n",
              "      <td id=\"T_8e03d_row0_col6\" class=\"data row0 col6\" >-0.03</td>\n",
              "      <td id=\"T_8e03d_row0_col7\" class=\"data row0 col7\" >0.02</td>\n",
              "      <td id=\"T_8e03d_row0_col8\" class=\"data row0 col8\" >-0.03</td>\n",
              "      <td id=\"T_8e03d_row0_col9\" class=\"data row0 col9\" >0.10</td>\n",
              "      <td id=\"T_8e03d_row0_col10\" class=\"data row0 col10\" >0.09</td>\n",
              "      <td id=\"T_8e03d_row0_col11\" class=\"data row0 col11\" >0.06</td>\n",
              "      <td id=\"T_8e03d_row0_col12\" class=\"data row0 col12\" >0.02</td>\n",
              "      <td id=\"T_8e03d_row0_col13\" class=\"data row0 col13\" >0.09</td>\n",
              "      <td id=\"T_8e03d_row0_col14\" class=\"data row0 col14\" >-0.00</td>\n",
              "      <td id=\"T_8e03d_row0_col15\" class=\"data row0 col15\" >-0.09</td>\n",
              "      <td id=\"T_8e03d_row0_col16\" class=\"data row0 col16\" >-0.03</td>\n",
              "      <td id=\"T_8e03d_row0_col17\" class=\"data row0 col17\" >0.07</td>\n",
              "      <td id=\"T_8e03d_row0_col18\" class=\"data row0 col18\" >-0.01</td>\n",
              "      <td id=\"T_8e03d_row0_col19\" class=\"data row0 col19\" >0.07</td>\n",
              "      <td id=\"T_8e03d_row0_col20\" class=\"data row0 col20\" >0.04</td>\n",
              "      <td id=\"T_8e03d_row0_col21\" class=\"data row0 col21\" >-0.01</td>\n",
              "      <td id=\"T_8e03d_row0_col22\" class=\"data row0 col22\" >0.06</td>\n",
              "      <td id=\"T_8e03d_row0_col23\" class=\"data row0 col23\" >-0.03</td>\n",
              "      <td id=\"T_8e03d_row0_col24\" class=\"data row0 col24\" >-0.05</td>\n",
              "      <td id=\"T_8e03d_row0_col25\" class=\"data row0 col25\" >-0.03</td>\n",
              "      <td id=\"T_8e03d_row0_col26\" class=\"data row0 col26\" >0.06</td>\n",
              "      <td id=\"T_8e03d_row0_col27\" class=\"data row0 col27\" >-0.00</td>\n",
              "      <td id=\"T_8e03d_row0_col28\" class=\"data row0 col28\" >0.03</td>\n",
              "      <td id=\"T_8e03d_row0_col29\" class=\"data row0 col29\" >-0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_8e03d_level0_row1\" class=\"row_heading level0 row1\" >ATTAGTAACGGAGGATTTAC...</th>\n",
              "      <td id=\"T_8e03d_row1_col0\" class=\"data row1 col0\" >-0.02</td>\n",
              "      <td id=\"T_8e03d_row1_col1\" class=\"data row1 col1\" >0.15</td>\n",
              "      <td id=\"T_8e03d_row1_col2\" class=\"data row1 col2\" >-0.02</td>\n",
              "      <td id=\"T_8e03d_row1_col3\" class=\"data row1 col3\" >0.02</td>\n",
              "      <td id=\"T_8e03d_row1_col4\" class=\"data row1 col4\" >-0.00</td>\n",
              "      <td id=\"T_8e03d_row1_col5\" class=\"data row1 col5\" >0.04</td>\n",
              "      <td id=\"T_8e03d_row1_col6\" class=\"data row1 col6\" >0.06</td>\n",
              "      <td id=\"T_8e03d_row1_col7\" class=\"data row1 col7\" >-0.02</td>\n",
              "      <td id=\"T_8e03d_row1_col8\" class=\"data row1 col8\" >0.01</td>\n",
              "      <td id=\"T_8e03d_row1_col9\" class=\"data row1 col9\" >0.05</td>\n",
              "      <td id=\"T_8e03d_row1_col10\" class=\"data row1 col10\" >0.09</td>\n",
              "      <td id=\"T_8e03d_row1_col11\" class=\"data row1 col11\" >0.02</td>\n",
              "      <td id=\"T_8e03d_row1_col12\" class=\"data row1 col12\" >0.01</td>\n",
              "      <td id=\"T_8e03d_row1_col13\" class=\"data row1 col13\" >0.06</td>\n",
              "      <td id=\"T_8e03d_row1_col14\" class=\"data row1 col14\" >-0.02</td>\n",
              "      <td id=\"T_8e03d_row1_col15\" class=\"data row1 col15\" >-0.05</td>\n",
              "      <td id=\"T_8e03d_row1_col16\" class=\"data row1 col16\" >0.01</td>\n",
              "      <td id=\"T_8e03d_row1_col17\" class=\"data row1 col17\" >0.02</td>\n",
              "      <td id=\"T_8e03d_row1_col18\" class=\"data row1 col18\" >-0.05</td>\n",
              "      <td id=\"T_8e03d_row1_col19\" class=\"data row1 col19\" >0.05</td>\n",
              "      <td id=\"T_8e03d_row1_col20\" class=\"data row1 col20\" >0.03</td>\n",
              "      <td id=\"T_8e03d_row1_col21\" class=\"data row1 col21\" >-0.03</td>\n",
              "      <td id=\"T_8e03d_row1_col22\" class=\"data row1 col22\" >0.03</td>\n",
              "      <td id=\"T_8e03d_row1_col23\" class=\"data row1 col23\" >-0.02</td>\n",
              "      <td id=\"T_8e03d_row1_col24\" class=\"data row1 col24\" >-0.03</td>\n",
              "      <td id=\"T_8e03d_row1_col25\" class=\"data row1 col25\" >-0.02</td>\n",
              "      <td id=\"T_8e03d_row1_col26\" class=\"data row1 col26\" >0.01</td>\n",
              "      <td id=\"T_8e03d_row1_col27\" class=\"data row1 col27\" >-0.02</td>\n",
              "      <td id=\"T_8e03d_row1_col28\" class=\"data row1 col28\" >0.06</td>\n",
              "      <td id=\"T_8e03d_row1_col29\" class=\"data row1 col29\" >-0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_8e03d_level0_row2\" class=\"row_heading level0 row2\" >AAAAAGCCGTAAAAGACGAT...</th>\n",
              "      <td id=\"T_8e03d_row2_col0\" class=\"data row2 col0\" >-0.02</td>\n",
              "      <td id=\"T_8e03d_row2_col1\" class=\"data row2 col1\" >0.11</td>\n",
              "      <td id=\"T_8e03d_row2_col2\" class=\"data row2 col2\" >-0.02</td>\n",
              "      <td id=\"T_8e03d_row2_col3\" class=\"data row2 col3\" >0.01</td>\n",
              "      <td id=\"T_8e03d_row2_col4\" class=\"data row2 col4\" >0.07</td>\n",
              "      <td id=\"T_8e03d_row2_col5\" class=\"data row2 col5\" >0.08</td>\n",
              "      <td id=\"T_8e03d_row2_col6\" class=\"data row2 col6\" >-0.04</td>\n",
              "      <td id=\"T_8e03d_row2_col7\" class=\"data row2 col7\" >-0.01</td>\n",
              "      <td id=\"T_8e03d_row2_col8\" class=\"data row2 col8\" >-0.01</td>\n",
              "      <td id=\"T_8e03d_row2_col9\" class=\"data row2 col9\" >0.09</td>\n",
              "      <td id=\"T_8e03d_row2_col10\" class=\"data row2 col10\" >0.10</td>\n",
              "      <td id=\"T_8e03d_row2_col11\" class=\"data row2 col11\" >0.01</td>\n",
              "      <td id=\"T_8e03d_row2_col12\" class=\"data row2 col12\" >0.02</td>\n",
              "      <td id=\"T_8e03d_row2_col13\" class=\"data row2 col13\" >0.06</td>\n",
              "      <td id=\"T_8e03d_row2_col14\" class=\"data row2 col14\" >0.01</td>\n",
              "      <td id=\"T_8e03d_row2_col15\" class=\"data row2 col15\" >-0.08</td>\n",
              "      <td id=\"T_8e03d_row2_col16\" class=\"data row2 col16\" >-0.03</td>\n",
              "      <td id=\"T_8e03d_row2_col17\" class=\"data row2 col17\" >0.05</td>\n",
              "      <td id=\"T_8e03d_row2_col18\" class=\"data row2 col18\" >-0.01</td>\n",
              "      <td id=\"T_8e03d_row2_col19\" class=\"data row2 col19\" >0.04</td>\n",
              "      <td id=\"T_8e03d_row2_col20\" class=\"data row2 col20\" >0.03</td>\n",
              "      <td id=\"T_8e03d_row2_col21\" class=\"data row2 col21\" >-0.01</td>\n",
              "      <td id=\"T_8e03d_row2_col22\" class=\"data row2 col22\" >0.04</td>\n",
              "      <td id=\"T_8e03d_row2_col23\" class=\"data row2 col23\" >-0.00</td>\n",
              "      <td id=\"T_8e03d_row2_col24\" class=\"data row2 col24\" >-0.04</td>\n",
              "      <td id=\"T_8e03d_row2_col25\" class=\"data row2 col25\" >-0.04</td>\n",
              "      <td id=\"T_8e03d_row2_col26\" class=\"data row2 col26\" >0.04</td>\n",
              "      <td id=\"T_8e03d_row2_col27\" class=\"data row2 col27\" >0.00</td>\n",
              "      <td id=\"T_8e03d_row2_col28\" class=\"data row2 col28\" >0.03</td>\n",
              "      <td id=\"T_8e03d_row2_col29\" class=\"data row2 col29\" >-0.03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "# transform data\n",
        "tEmb1 = scaler.fit_transform(tEmb)\n",
        "vEmb1= scaler.transform(vEmb)\n",
        "print(vEmb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUZWJ0DbUjwf",
        "outputId": "84ffd27a-9078-4e53-d413-328ffaf6009d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.0272  0.1095 -0.0199  0.0415  0.0524  0.0924 -0.0284  0.0183 -0.0251  0.1014  0.0885  0.0599  0.0234  0.0863 -0.0032 -0.0892 -0.0289  0.0708 -0.0078  0.0717 ...  0.029  -0.1178 -0.0271 -0.0097 -0.0019  0.0399 -0.0399 -0.0187 -0.0628  0.0053  0.0072  0.0787 -0.0182 -0.017   0.0352  0.159  -0.0054  0.084  -0.0731 -0.0661]\n",
            " [-0.0164  0.1469 -0.0212  0.0188 -0.0001  0.0359  0.056  -0.0213  0.014   0.05    0.0897  0.0154  0.0079  0.0637 -0.018  -0.0503  0.0128  0.0225 -0.0474  0.0546 ...  0.0323 -0.0738 -0.0324  0.0172 -0.0099  0.0224 -0.024  -0.0139 -0.065   0.01    0.0214  0.0145  0.0044  0.0039  0.0272  0.0241  0.0165  0.0524 -0.0328 -0.0175]\n",
            " [-0.0199  0.1127 -0.021   0.0139  0.0674  0.0784 -0.0399 -0.0109 -0.0135  0.0904  0.1025  0.0088  0.0226  0.0557  0.0124 -0.0778 -0.0288  0.0542 -0.0103  0.0407 ...  0.04   -0.1237 -0.0061  0.0155 -0.0104  0.0149 -0.0842 -0.0251 -0.0927  0.0017  0.0205  0.0532 -0.0276 -0.0142  0.0364  0.1013 -0.007   0.0468 -0.0562 -0.0743]\n",
            " [ 0.0053  0.1841 -0.0192  0.009   0.0547  0.1487 -0.07    0.0342 -0.0121  0.1614  0.1438  0.0956  0.0292  0.0222 -0.0014 -0.0732 -0.049   0.1115  0.0477  0.0467 ...  0.1191 -0.1575  0.0259  0.0651 -0.0204  0.0215 -0.0204 -0.0297 -0.0422  0.0153  0.0549  0.0699  0.018  -0.0148  0.0522  0.1425 -0.0213  0.069  -0.0928 -0.1328]\n",
            " [ 0.0182  0.1252 -0.0186  0.0046  0.0567  0.1512 -0.1188  0.0498 -0.0244  0.1273  0.1098  0.1196  0.0273  0.02   -0.0047 -0.0933 -0.0808  0.1223  0.0219  0.064  ...  0.0886 -0.1485  0.0502  0.0616 -0.0083  0.0067 -0.0296 -0.0394 -0.0519  0.0215  0.0368  0.114   0.0149 -0.0067  0.081   0.2057 -0.0342  0.0572 -0.1253 -0.1214]\n",
            " [-0.0233  0.0454 -0.018   0.0239  0.0702  0.0867 -0.0602  0.0068 -0.0274  0.0968  0.0626  0.0299  0.0354  0.1167 -0.0087 -0.0684 -0.038   0.0708 -0.0379  0.0839 ...  0.0304 -0.1414 -0.0326  0.001  -0.0699  0.0444 -0.0875 -0.0423 -0.128  -0.0123 -0.0323  0.1145 -0.0391 -0.0335  0.067   0.2276 -0.0193  0.0584 -0.0999 -0.0632]\n",
            " [ 0.0066  0.1512 -0.0192 -0.0166  0.0709  0.1517 -0.0763  0.0234  0.0165  0.1605  0.1472  0.0981  0.038  -0.0182 -0.0221 -0.0627 -0.0422  0.1304  0.0277  0.0536 ...  0.1111 -0.1554  0.0219  0.0548 -0.0126  0.0301 -0.0015 -0.0207 -0.0511  0.0076  0.0457  0.0744 -0.011  -0.0346  0.0558  0.1466 -0.0242  0.0756 -0.0949 -0.1421]\n",
            " [-0.0033  0.1626 -0.0195  0.0022  0.0682  0.1348 -0.082   0.0138 -0.0195  0.1561  0.1335  0.0964  0.0425  0.0367 -0.0199 -0.0531 -0.0565  0.0985  0.046   0.0448 ...  0.0993 -0.1521  0.0189  0.0475 -0.0021  0.0244 -0.0279 -0.0164 -0.0561  0.0111  0.0345  0.0729 -0.0043 -0.0257  0.0501  0.1647 -0.0217  0.0702 -0.085  -0.1244]\n",
            " [-0.0005  0.158  -0.0187  0.0413  0.0851  0.1479 -0.083   0.0338  0.0019  0.1195  0.1209  0.087   0.039   0.0371  0.0212 -0.0991 -0.0545  0.096   0.029   0.0561 ...  0.1158 -0.1564 -0.0095  0.0374  0.0391  0.0171 -0.039  -0.0465 -0.0655  0.0217  0.0411  0.0921  0.0349 -0.0216  0.0547  0.1569 -0.0324  0.0583 -0.098  -0.1209]\n",
            " [-0.0191  0.0816 -0.0186  0.0509  0.058   0.0941 -0.0499  0.011  -0.0457  0.0856  0.0778  0.0469  0.0249  0.0951 -0.0194 -0.08   -0.0324  0.0639 -0.0642  0.078  ...  0.0389 -0.1236 -0.0445 -0.0123 -0.0293  0.0399 -0.0519 -0.0298 -0.0947  0.0002 -0.005   0.0792 -0.0132 -0.0109  0.0469  0.1791 -0.0074  0.086  -0.0936 -0.0564]\n",
            " [-0.0164  0.0942 -0.0193  0.0388  0.0597  0.1069 -0.0408  0.0269  0.0527  0.1094  0.1025  0.0718  0.0374  0.0911  0.0219 -0.1014 -0.0102  0.0615  0.0404  0.0677 ...  0.0306 -0.1422 -0.0367  0.0237  0.035   0.0214 -0.0542 -0.0366 -0.0814  0.0379  0.03    0.0755  0.0136 -0.0098  0.0501  0.0327  0.001   0.0765 -0.0722 -0.0828]\n",
            " [-0.0113  0.1693 -0.0184  0.0206  0.0821  0.138  -0.1204  0.0303 -0.016   0.1343  0.1355  0.077   0.0421  0.031   0.0281 -0.0828 -0.0412  0.0973 -0.0252  0.0382 ...  0.1264 -0.1567  0.0182  0.0442  0.0065  0.0165 -0.0355 -0.0418 -0.0649  0.0393  0.0553  0.1065  0.0307 -0.0203  0.0582  0.1266 -0.0414  0.0476 -0.1034 -0.132 ]\n",
            " [-0.0177  0.1409 -0.017   0.0596  0.0812  0.1576 -0.0981  0.0622  0.0349  0.1413  0.1501  0.1249  0.0349  0.0581 -0.0015 -0.0728 -0.0687  0.1003  0.0146  0.0677 ...  0.1517 -0.1521 -0.017   0.0591  0.0586  0.0211 -0.0422 -0.0508 -0.0729  0.0043  0.0435  0.1032  0.0482 -0.0079  0.0583  0.2177 -0.0499  0.0599 -0.1185 -0.1406]\n",
            " [-0.0036  0.0568 -0.0196  0.033   0.0832  0.0817 -0.0632 -0.0012 -0.0474  0.0846  0.0622  0.0292  0.0104  0.0504  0.0218 -0.1076 -0.0509  0.0652 -0.0485  0.0553 ...  0.0459 -0.1395  0.0077 -0.0114 -0.0313  0.023  -0.0974 -0.0532 -0.1051  0.0035 -0.0203  0.0847 -0.015  -0.0138  0.0491  0.1816 -0.0141  0.054  -0.0713 -0.0626]\n",
            " [-0.0092  0.1234 -0.0198  0.0051  0.0759  0.1049 -0.0582 -0.0073 -0.0267  0.1019  0.0931  0.0247  0.0333  0.0454  0.0069 -0.0771 -0.0411  0.0712  0.0198  0.03   ...  0.0746 -0.1521  0.0177  0.0228 -0.002   0.0142 -0.0797 -0.0362 -0.0871  0.0141  0.0149  0.059  -0.0141 -0.0185  0.0487  0.1259 -0.0054  0.0483 -0.0555 -0.0842]\n",
            " [-0.0484  0.0966 -0.0183  0.0991  0.0771  0.1165 -0.0379  0.0372  0.0288  0.0646  0.1172  0.0726  0.0381  0.1235  0.0208 -0.1139 -0.0279  0.0581 -0.0081  0.0751 ...  0.0888 -0.1326 -0.0589  0.0056  0.0704  0.0225 -0.0518 -0.0511 -0.0985  0.0093  0.0248  0.0925  0.0532 -0.0024  0.0488  0.1287 -0.0241  0.0595 -0.0892 -0.0871]\n",
            " [-0.0344  0.1232 -0.0203  0.0279  0.0388  0.0871 -0.0204 -0.0093  0.0078  0.1176  0.1031  0.046   0.0281  0.0377 -0.0017 -0.057  -0.0124  0.0853 -0.063   0.0614 ...  0.0787 -0.1224 -0.0267  0.0193 -0.06    0.0309 -0.0116 -0.0441 -0.0803 -0.0071  0.0273  0.0567 -0.047  -0.0104  0.0363  0.1164 -0.0094  0.0523 -0.0563 -0.0884]\n",
            " [ 0.0202  0.1797 -0.0183 -0.0177  0.0802  0.1552 -0.0996  0.0412 -0.0144  0.1623  0.1478  0.114   0.0362 -0.0113 -0.0036 -0.0821 -0.0733  0.1206  0.0409  0.0447 ...  0.1407 -0.1593  0.0428  0.0777  0.0215  0.0093 -0.032  -0.0368 -0.0421  0.0282  0.0613  0.0821  0.0191 -0.0218  0.0627  0.1442 -0.0423  0.0559 -0.103  -0.1446]\n",
            " [-0.0032  0.169  -0.0203 -0.002   0.0706  0.1205 -0.0665  0.0161 -0.0106  0.1322  0.1253  0.0879  0.0241  0.0411 -0.0021 -0.0598 -0.0537  0.1086  0.0472  0.0399 ...  0.0865 -0.16    0.0237  0.0461  0.0144  0.0228 -0.03   -0.0203 -0.0452  0.0072  0.0449  0.058  -0.0095 -0.025   0.0527  0.1659 -0.0107  0.064  -0.0795 -0.1039]\n",
            " [-0.016   0.1488 -0.0204  0.0277  0.0733  0.1109 -0.059   0.0141 -0.0328  0.1187  0.1157  0.0539  0.0249  0.0409  0.0087 -0.1113 -0.0435  0.0876  0.0077  0.0482 ...  0.0563 -0.1501  0.0152  0.0096  0.0239  0.021  -0.0348 -0.0242 -0.0443  0.0139  0.0417  0.0569 -0.0143 -0.0147  0.0456  0.0988 -0.0136  0.069  -0.0722 -0.0973]\n",
            " ...\n",
            " [-0.0294  0.1139 -0.0208  0.0266  0.0575  0.0624 -0.0115 -0.0184 -0.0215  0.076   0.0912  0.0121  0.0308  0.0887 -0.0062 -0.0619 -0.0155  0.0325 -0.0114  0.0542 ...  0.0246 -0.0996 -0.0333  0.0087  0.0017  0.027  -0.0922 -0.0141 -0.0826  0.0081  0.016   0.05   -0.0096 -0.007   0.0297  0.0932  0.0063  0.051  -0.0476 -0.0477]\n",
            " [-0.0033  0.1803 -0.0186  0.007   0.0671  0.1368 -0.1191  0.0186 -0.0018  0.148   0.1428  0.0858  0.0343  0.0139  0.0038 -0.0598 -0.0459  0.1048 -0.0048  0.0453 ...  0.1146 -0.1563  0.0347  0.0602  0.0018  0.018  -0.0281 -0.0295 -0.0601  0.0319  0.0514  0.0965  0.0023 -0.0247  0.0622  0.1682 -0.0289  0.0415 -0.1201 -0.1379]\n",
            " [-0.0412  0.1058 -0.0202  0.01    0.0619  0.0687 -0.0075  0.0042  0.0248  0.0682  0.0923  0.014   0.032   0.1    -0.0005 -0.0766 -0.0021  0.0452 -0.0317  0.0621 ...  0.026  -0.097  -0.0625  0.0101 -0.047   0.0289 -0.0456 -0.0373 -0.1177 -0.0101  0.0128  0.0415 -0.0362 -0.0175  0.031   0.0862  0.0023  0.0542 -0.0579 -0.0518]\n",
            " [ 0.0075  0.178  -0.0191  0.0091  0.0714  0.1402 -0.0823  0.0302 -0.0172  0.1287  0.13    0.0837  0.0312  0.0033  0.0126 -0.0864 -0.0456  0.1     0.0089  0.0348 ...  0.115  -0.1588  0.0273  0.0602  0.017   0.0159 -0.0292 -0.0331 -0.0563  0.0371  0.0561  0.0787  0.0197 -0.0115  0.0577  0.122  -0.0251  0.0503 -0.0957 -0.1281]\n",
            " [-0.0097  0.1613 -0.0197  0.0301  0.0743  0.1341 -0.046   0.0312 -0.033   0.1674  0.1204  0.0552  0.0675 -0.0087  0.033  -0.0641 -0.0666  0.1054  0.0263  0.0596 ...  0.0737 -0.1664  0.0107  0.0293  0.0327  0.029  -0.0339 -0.0341 -0.0232  0.0212  0.0756  0.0623  0.0155 -0.0166  0.05    0.1208 -0.0214  0.0901 -0.11   -0.1158]\n",
            " [-0.0355  0.1181 -0.0205  0.0045  0.0506  0.0793 -0.0303 -0.0021  0.0253  0.1021  0.1111  0.0399  0.032   0.0798 -0.0077 -0.0653  0.0054  0.0619 -0.0107  0.0536 ...  0.0387 -0.13   -0.0388  0.0153 -0.0576  0.0295 -0.0516 -0.0348 -0.0955 -0.0012  0.0109  0.05   -0.048  -0.0212  0.0423  0.0914  0.0011  0.0517 -0.0669 -0.0682]\n",
            " [-0.0207  0.0799 -0.0188  0.0433  0.0663  0.1088 -0.0605  0.0164 -0.0298  0.1128  0.0841  0.0569  0.0375  0.0813 -0.0104 -0.0844 -0.0393  0.0769 -0.0188  0.0683 ...  0.0398 -0.1379 -0.0284  0.0049 -0.041   0.0373 -0.0611 -0.0286 -0.0814  0.0009 -0.0017  0.0963 -0.0297 -0.0244  0.0525  0.1908 -0.0137  0.0826 -0.0962 -0.081 ]\n",
            " [-0.0203  0.1211 -0.0208  0.0622  0.0594  0.0714 -0.0111  0.0057  0.0259  0.0476  0.0948  0.0348  0.0124  0.0664  0.0249 -0.0853 -0.0203  0.0342 -0.0539  0.0487 ...  0.0627 -0.1087 -0.0024  0.0186  0.0137  0.0107 -0.042  -0.0475 -0.083   0.0041  0.0382  0.0441  0.0275  0.0077  0.0265  0.0571 -0.0056  0.0326 -0.0497 -0.0573]\n",
            " [ 0.0014  0.1556 -0.02    0.0206  0.0592  0.1275 -0.0538  0.0326 -0.0189  0.1304  0.1244  0.0714  0.031   0.0456  0.009  -0.109  -0.0385  0.0976  0.0183  0.0515 ...  0.0867 -0.1491 -0.0083  0.0322 -0.0085  0.0155 -0.0325 -0.0339 -0.0522  0.0215  0.0453  0.0687  0.003  -0.0178  0.0526  0.1108 -0.0183  0.0687 -0.0793 -0.1031]\n",
            " [ 0.0046  0.1626 -0.0183  0.003   0.0635  0.1409 -0.1132  0.0322 -0.0016  0.165   0.1516  0.1058  0.0378  0.0316 -0.0079 -0.0604 -0.0564  0.1056  0.0161  0.0539 ...  0.1339 -0.1539  0.0268  0.0657  0.0047  0.0187 -0.0304 -0.0276 -0.0526  0.0207  0.0491  0.09   -0.0044 -0.0163  0.0627  0.1714 -0.0363  0.0556 -0.1206 -0.1374]\n",
            " [-0.0138  0.1268 -0.0189  0.002   0.0801  0.1306 -0.1006  0.0172  0.0051  0.1467  0.1315  0.0674  0.0447 -0.0074 -0.0048 -0.0591 -0.0175  0.1131  0.0117  0.048  ...  0.0752 -0.161   0.0226  0.0341 -0.0423  0.032  -0.0301 -0.0235 -0.0753  0.0146  0.0239  0.0798 -0.026  -0.0415  0.0599  0.1562 -0.0224  0.0675 -0.09   -0.1311]\n",
            " [ 0.0058  0.1516 -0.0186 -0.0055  0.0711  0.14   -0.1117  0.0206 -0.0132  0.1611  0.1496  0.0873  0.0354  0.006  -0.0119 -0.0645 -0.0582  0.1082  0.0239  0.0555 ...  0.1191 -0.1698  0.0249  0.0631 -0.0105  0.0245 -0.0249 -0.037  -0.049   0.0128  0.0421  0.0973 -0.0116 -0.0327  0.0631  0.1956 -0.0262  0.0544 -0.1201 -0.1412]\n",
            " [ 0.0004  0.1852 -0.0197  0.0255  0.0621  0.139  -0.0776  0.0442 -0.0086  0.1341  0.1383  0.1006  0.0293 -0.0022  0.0172 -0.0992 -0.0468  0.1174  0.0271  0.0475 ...  0.1046 -0.1476  0.0256  0.0575  0.038   0.0145 -0.0002 -0.0292 -0.0315  0.0293  0.0719  0.0682  0.0175 -0.0118  0.0565  0.1288 -0.0244  0.0636 -0.0922 -0.13  ]\n",
            " [-0.0347  0.1003 -0.0207  0.0249  0.0457  0.0596  0.0017 -0.0027 -0.0061  0.0635  0.0871 -0.007   0.0195  0.0885  0.0061 -0.0726 -0.0143  0.0313 -0.0459  0.0582 ...  0.0353 -0.0941 -0.0364  0.014  -0.0363  0.0216 -0.0672 -0.034  -0.1098 -0.0062  0.0148  0.0402 -0.0182 -0.0115  0.0227  0.0524 -0.0003  0.04   -0.0466 -0.0472]\n",
            " [ 0.0033  0.182  -0.0189  0.0049  0.0762  0.1399 -0.0999  0.0328 -0.0145  0.1396  0.1361  0.0957  0.0343  0.022   0.01   -0.0851 -0.0505  0.1039  0.0256  0.0366 ...  0.1139 -0.1582  0.0399  0.0601  0.024   0.0065 -0.0272 -0.0355 -0.0507  0.0308  0.0611  0.084   0.0197 -0.0156  0.059   0.131  -0.0339  0.049  -0.105  -0.1341]\n",
            " [-0.003   0.1846 -0.0187  0.0194  0.0734  0.1292 -0.1077  0.0403 -0.0016  0.1224  0.1207  0.0828  0.0279  0.0253  0.0308 -0.0965 -0.0406  0.1045 -0.0212  0.0361 ...  0.1006 -0.1463  0.0201  0.0487  0.031   0.006  -0.0243 -0.0335 -0.0619  0.0371  0.067   0.0881  0.0247 -0.0135  0.0518  0.1129 -0.0309  0.0419 -0.1042 -0.1262]\n",
            " [ 0.007   0.1452 -0.0184  0.0211  0.0578  0.1515 -0.1152  0.063  -0.0208  0.1312  0.1185  0.1406  0.0241  0.0345 -0.0005 -0.0845 -0.0714  0.1221  0.0136  0.0717 ...  0.0872 -0.1507  0.0347  0.0638 -0.0058  0.0065 -0.0187 -0.0347 -0.0532  0.0214  0.0406  0.1121  0.0145  0.0036  0.0814  0.2133 -0.0372  0.0621 -0.1364 -0.1314]\n",
            " [-0.0006  0.1561 -0.0192  0.018   0.0635  0.1657 -0.0437  0.0363 -0.0224  0.2014  0.1378  0.0849  0.0734 -0.0176  0.0153 -0.0357 -0.0769  0.115   0.033   0.0602 ...  0.0997 -0.1673  0.0042  0.0505  0.0122  0.0322 -0.0319 -0.0398 -0.0242  0.022   0.082   0.0656  0.0011 -0.0186  0.0606  0.1571 -0.0315  0.0861 -0.133  -0.1264]\n",
            " [-0.0069  0.1481 -0.0171  0.0165  0.0679  0.1197 -0.1048  0.0501  0.0212  0.1755  0.143   0.1177  0.0262  0.0378  0.0128 -0.039  -0.0365  0.1189 -0.0169  0.0682 ...  0.1108 -0.1666 -0.0211  0.0544 -0.0327  0.0202 -0.003  -0.048  -0.0533  0.0053  0.0362  0.0947 -0.0122 -0.0228  0.0673  0.1879 -0.0362  0.0587 -0.1206 -0.1479]\n",
            " [ 0.0162  0.1832 -0.019  -0.0046  0.0742  0.1514 -0.0906  0.0403 -0.0053  0.1551  0.1495  0.1115  0.0292  0.003   0.0029 -0.089  -0.0629  0.1147  0.0352  0.0406 ...  0.1274 -0.1557  0.0401  0.0608  0.0279  0.0077 -0.0185 -0.038  -0.0478  0.022   0.0676  0.0809  0.0154 -0.0176  0.0594  0.1412 -0.0348  0.0498 -0.0999 -0.1374]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7S-L3EFJHqB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3df331a5-1d9f-4ce1-b105-0f6113ad1c8a"
      },
      "source": [
        "m = LinearSVC(random_state=0, class_weight='balanced', max_iter=20000, C=100).fit(tEmb1, tYX.Y)  # SVC is ok to use. See updated Rules.=\n",
        "m.score(tEmb1, tYX.Y)   # in-sample accuracy\n",
        "from sklearn.model_selection import GridSearchCV\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9973"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "w4H0LKZNUHog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print best parameter after tuning\n",
        "print(grid.best_params_)\n",
        "  \n",
        "# print how our model looks after hyper-parameter tuning\n",
        "print(grid.best_estimator_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ln-Dh-4t5qUA",
        "outputId": "41a7f127-8bc0-43b6-b356-66e62b26f4e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}\n",
            "SVC(C=100, gamma=0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# defining parameter range\n",
        "param_grid = {'C': [0.1, 1, 10, 100, 1000], \n",
        "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "              'kernel': ['linear']} \n",
        "  \n",
        "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3)\n",
        "  \n",
        "# fitting the model for grid search\n",
        "grid.fit(tEmb, tYX.Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9T8r2p149rP",
        "outputId": "9b562edb-d25f-478d-f4cc-6e84a4635af5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
            "[CV 1/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.971 total time=   3.8s\n",
            "[CV 2/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.973 total time=   3.8s\n",
            "[CV 3/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.977 total time=   3.9s\n",
            "[CV 4/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.972 total time=   3.9s\n",
            "[CV 5/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.975 total time=   3.9s\n",
            "[CV 1/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.971 total time=   3.9s\n",
            "[CV 2/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.973 total time=   3.9s\n",
            "[CV 3/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.977 total time=   3.8s\n",
            "[CV 4/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.972 total time=   3.8s\n",
            "[CV 5/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.975 total time=   4.9s\n",
            "[CV 1/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.971 total time=   4.1s\n",
            "[CV 2/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.973 total time=   4.2s\n",
            "[CV 3/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.977 total time=   3.8s\n",
            "[CV 4/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.972 total time=   3.8s\n",
            "[CV 5/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.975 total time=   3.9s\n",
            "[CV 1/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.971 total time=   3.8s\n",
            "[CV 2/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.973 total time=   3.9s\n",
            "[CV 3/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.977 total time=   3.9s\n",
            "[CV 4/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.972 total time=   3.8s\n",
            "[CV 5/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.975 total time=   4.0s\n",
            "[CV 1/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.971 total time=   3.8s\n",
            "[CV 2/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.973 total time=   3.8s\n",
            "[CV 3/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.977 total time=   3.9s\n",
            "[CV 4/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.972 total time=   3.8s\n",
            "[CV 5/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.975 total time=   3.9s\n",
            "[CV 1/5] END .......C=1, gamma=1, kernel=linear;, score=0.977 total time=   2.4s\n",
            "[CV 2/5] END .......C=1, gamma=1, kernel=linear;, score=0.979 total time=   2.4s\n",
            "[CV 3/5] END .......C=1, gamma=1, kernel=linear;, score=0.981 total time=   2.4s\n",
            "[CV 4/5] END .......C=1, gamma=1, kernel=linear;, score=0.978 total time=   2.5s\n",
            "[CV 5/5] END .......C=1, gamma=1, kernel=linear;, score=0.978 total time=   2.4s\n",
            "[CV 1/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.977 total time=   2.4s\n",
            "[CV 2/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.979 total time=   2.5s\n",
            "[CV 3/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.981 total time=   2.5s\n",
            "[CV 4/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.978 total time=   2.4s\n",
            "[CV 5/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.978 total time=   2.4s\n",
            "[CV 1/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.977 total time=   2.4s\n",
            "[CV 2/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.979 total time=   2.4s\n",
            "[CV 3/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.981 total time=   2.4s\n",
            "[CV 4/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.978 total time=   2.4s\n",
            "[CV 5/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.978 total time=   2.4s\n",
            "[CV 1/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.977 total time=   2.4s\n",
            "[CV 2/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.979 total time=   2.4s\n",
            "[CV 3/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.981 total time=   2.4s\n",
            "[CV 4/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.978 total time=   2.4s\n",
            "[CV 5/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.978 total time=   2.4s\n",
            "[CV 1/5] END ..C=1, gamma=0.0001, kernel=linear;, score=0.977 total time=   2.3s\n",
            "[CV 2/5] END ..C=1, gamma=0.0001, kernel=linear;, score=0.979 total time=   2.4s\n",
            "[CV 3/5] END ..C=1, gamma=0.0001, kernel=linear;, score=0.981 total time=   3.3s\n",
            "[CV 4/5] END ..C=1, gamma=0.0001, kernel=linear;, score=0.978 total time=   2.4s\n",
            "[CV 5/5] END ..C=1, gamma=0.0001, kernel=linear;, score=0.978 total time=   2.3s\n",
            "[CV 1/5] END ......C=10, gamma=1, kernel=linear;, score=0.978 total time=   2.0s\n",
            "[CV 2/5] END ......C=10, gamma=1, kernel=linear;, score=0.981 total time=   2.0s\n",
            "[CV 3/5] END ......C=10, gamma=1, kernel=linear;, score=0.980 total time=   2.0s\n",
            "[CV 4/5] END ......C=10, gamma=1, kernel=linear;, score=0.982 total time=   2.1s\n",
            "[CV 5/5] END ......C=10, gamma=1, kernel=linear;, score=0.980 total time=   2.5s\n",
            "[CV 1/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.978 total time=   2.0s\n",
            "[CV 2/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.981 total time=   2.0s\n",
            "[CV 3/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.980 total time=   2.0s\n",
            "[CV 4/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.982 total time=   2.0s\n",
            "[CV 5/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.980 total time=   1.9s\n",
            "[CV 1/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.978 total time=   1.9s\n",
            "[CV 2/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.981 total time=   2.0s\n",
            "[CV 3/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.980 total time=   2.0s\n",
            "[CV 4/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.982 total time=   2.0s\n",
            "[CV 5/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.980 total time=   1.9s\n",
            "[CV 1/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.978 total time=   2.0s\n",
            "[CV 2/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.981 total time=   2.0s\n",
            "[CV 3/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.980 total time=   2.0s\n",
            "[CV 4/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.982 total time=   2.1s\n",
            "[CV 5/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.980 total time=   2.0s\n",
            "[CV 1/5] END .C=10, gamma=0.0001, kernel=linear;, score=0.978 total time=   2.0s\n",
            "[CV 2/5] END .C=10, gamma=0.0001, kernel=linear;, score=0.981 total time=   2.0s\n",
            "[CV 3/5] END .C=10, gamma=0.0001, kernel=linear;, score=0.980 total time=   2.0s\n",
            "[CV 4/5] END .C=10, gamma=0.0001, kernel=linear;, score=0.982 total time=   2.0s\n",
            "[CV 5/5] END .C=10, gamma=0.0001, kernel=linear;, score=0.980 total time=   2.0s\n",
            "[CV 1/5] END .....C=100, gamma=1, kernel=linear;, score=0.977 total time=   2.2s\n",
            "[CV 2/5] END .....C=100, gamma=1, kernel=linear;, score=0.976 total time=   2.2s\n",
            "[CV 3/5] END .....C=100, gamma=1, kernel=linear;, score=0.980 total time=   2.2s\n",
            "[CV 4/5] END .....C=100, gamma=1, kernel=linear;, score=0.981 total time=   2.3s\n",
            "[CV 5/5] END .....C=100, gamma=1, kernel=linear;, score=0.980 total time=   2.2s\n",
            "[CV 1/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.977 total time=   2.3s\n",
            "[CV 2/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.976 total time=   2.2s\n",
            "[CV 3/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.980 total time=   2.2s\n",
            "[CV 4/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.981 total time=   2.3s\n",
            "[CV 5/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.980 total time=   2.2s\n",
            "[CV 1/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.977 total time=   2.3s\n",
            "[CV 2/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.976 total time=   2.2s\n",
            "[CV 3/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.980 total time=   2.2s\n",
            "[CV 4/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.981 total time=   2.3s\n",
            "[CV 5/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.980 total time=   2.3s\n",
            "[CV 1/5] END .C=100, gamma=0.001, kernel=linear;, score=0.977 total time=   2.3s\n",
            "[CV 2/5] END .C=100, gamma=0.001, kernel=linear;, score=0.976 total time=   2.2s\n",
            "[CV 3/5] END .C=100, gamma=0.001, kernel=linear;, score=0.980 total time=   2.6s\n",
            "[CV 4/5] END .C=100, gamma=0.001, kernel=linear;, score=0.981 total time=   2.6s\n",
            "[CV 5/5] END .C=100, gamma=0.001, kernel=linear;, score=0.980 total time=   2.2s\n",
            "[CV 1/5] END C=100, gamma=0.0001, kernel=linear;, score=0.977 total time=   2.2s\n",
            "[CV 2/5] END C=100, gamma=0.0001, kernel=linear;, score=0.976 total time=   2.3s\n",
            "[CV 3/5] END C=100, gamma=0.0001, kernel=linear;, score=0.980 total time=   2.2s\n",
            "[CV 4/5] END C=100, gamma=0.0001, kernel=linear;, score=0.981 total time=   2.2s\n",
            "[CV 5/5] END C=100, gamma=0.0001, kernel=linear;, score=0.980 total time=   2.2s\n",
            "[CV 1/5] END ....C=1000, gamma=1, kernel=linear;, score=0.977 total time=   3.8s\n",
            "[CV 2/5] END ....C=1000, gamma=1, kernel=linear;, score=0.976 total time=   3.6s\n",
            "[CV 3/5] END ....C=1000, gamma=1, kernel=linear;, score=0.976 total time=   3.6s\n",
            "[CV 4/5] END ....C=1000, gamma=1, kernel=linear;, score=0.975 total time=   3.7s\n",
            "[CV 5/5] END ....C=1000, gamma=1, kernel=linear;, score=0.975 total time=   3.6s\n",
            "[CV 1/5] END ..C=1000, gamma=0.1, kernel=linear;, score=0.977 total time=   3.8s\n",
            "[CV 2/5] END ..C=1000, gamma=0.1, kernel=linear;, score=0.976 total time=   3.7s\n",
            "[CV 3/5] END ..C=1000, gamma=0.1, kernel=linear;, score=0.976 total time=   3.7s\n",
            "[CV 4/5] END ..C=1000, gamma=0.1, kernel=linear;, score=0.975 total time=   3.7s\n",
            "[CV 5/5] END ..C=1000, gamma=0.1, kernel=linear;, score=0.975 total time=   3.6s\n",
            "[CV 1/5] END .C=1000, gamma=0.01, kernel=linear;, score=0.977 total time=   3.8s\n",
            "[CV 2/5] END .C=1000, gamma=0.01, kernel=linear;, score=0.976 total time=   3.6s\n",
            "[CV 3/5] END .C=1000, gamma=0.01, kernel=linear;, score=0.976 total time=   3.8s\n",
            "[CV 4/5] END .C=1000, gamma=0.01, kernel=linear;, score=0.975 total time=   3.7s\n",
            "[CV 5/5] END .C=1000, gamma=0.01, kernel=linear;, score=0.975 total time=   3.6s\n",
            "[CV 1/5] END C=1000, gamma=0.001, kernel=linear;, score=0.977 total time=   3.8s\n",
            "[CV 2/5] END C=1000, gamma=0.001, kernel=linear;, score=0.976 total time=   3.6s\n",
            "[CV 3/5] END C=1000, gamma=0.001, kernel=linear;, score=0.976 total time=   3.6s\n",
            "[CV 4/5] END C=1000, gamma=0.001, kernel=linear;, score=0.975 total time=   3.7s\n",
            "[CV 5/5] END C=1000, gamma=0.001, kernel=linear;, score=0.975 total time=   3.5s\n",
            "[CV 1/5] END C=1000, gamma=0.0001, kernel=linear;, score=0.977 total time=   3.8s\n",
            "[CV 2/5] END C=1000, gamma=0.0001, kernel=linear;, score=0.976 total time=   3.7s\n",
            "[CV 3/5] END C=1000, gamma=0.0001, kernel=linear;, score=0.976 total time=   3.8s\n",
            "[CV 4/5] END C=1000, gamma=0.0001, kernel=linear;, score=0.975 total time=   3.7s\n",
            "[CV 5/5] END C=1000, gamma=0.0001, kernel=linear;, score=0.975 total time=   3.5s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(estimator=SVC(),\n",
              "             param_grid={'C': [0.1, 1, 10, 100, 1000],\n",
              "                         'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
              "                         'kernel': ['linear']},\n",
              "             verbose=3)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print best parameter after tuning\n",
        "print(grid.best_params_)\n",
        "  \n",
        "# print how our model looks after hyper-parameter tuning\n",
        "print(grid.best_estimator_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqEN23dK5uyi",
        "outputId": "71a3f09b-eb35-40d9-a9e4-4507a0643ffa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'C': 10, 'gamma': 1, 'kernel': 'linear'}\n",
            "SVC(C=10, gamma=1, kernel='linear')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# defining parameter range\n",
        "param_grid = {'C': [0.1, 1, 10, 100, 1000], \n",
        "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "              'degree':[2,3],\n",
        "              'kernel': ['poly']} \n",
        "  \n",
        "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3)\n",
        "  \n",
        "# fitting the model for grid search\n",
        "grid.fit(tEmb, tYX.Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QZEPZ685ven",
        "outputId": "8fe3a608-b1f4-46ff-cedd-0834e392b2ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "[CV 1/5] END C=0.1, degree=2, gamma=1, kernel=poly;, score=0.977 total time=   2.9s\n",
            "[CV 2/5] END C=0.1, degree=2, gamma=1, kernel=poly;, score=0.980 total time=   2.5s\n",
            "[CV 3/5] END C=0.1, degree=2, gamma=1, kernel=poly;, score=0.981 total time=   2.6s\n",
            "[CV 4/5] END C=0.1, degree=2, gamma=1, kernel=poly;, score=0.978 total time=   2.5s\n",
            "[CV 5/5] END C=0.1, degree=2, gamma=1, kernel=poly;, score=0.978 total time=   2.5s\n",
            "[CV 1/5] END C=0.1, degree=2, gamma=0.1, kernel=poly;, score=0.963 total time=   8.6s\n",
            "[CV 2/5] END C=0.1, degree=2, gamma=0.1, kernel=poly;, score=0.965 total time=   8.7s\n",
            "[CV 3/5] END C=0.1, degree=2, gamma=0.1, kernel=poly;, score=0.969 total time=   8.5s\n",
            "[CV 4/5] END C=0.1, degree=2, gamma=0.1, kernel=poly;, score=0.965 total time=   8.7s\n",
            "[CV 5/5] END C=0.1, degree=2, gamma=0.1, kernel=poly;, score=0.968 total time=   8.6s\n",
            "[CV 1/5] END C=0.1, degree=2, gamma=0.01, kernel=poly;, score=0.500 total time=  31.8s\n",
            "[CV 2/5] END C=0.1, degree=2, gamma=0.01, kernel=poly;, score=0.500 total time=  31.6s\n",
            "[CV 3/5] END C=0.1, degree=2, gamma=0.01, kernel=poly;, score=0.500 total time=  31.7s\n",
            "[CV 4/5] END C=0.1, degree=2, gamma=0.01, kernel=poly;, score=0.500 total time=  31.6s\n",
            "[CV 5/5] END C=0.1, degree=2, gamma=0.01, kernel=poly;, score=0.501 total time=  31.7s\n",
            "[CV 1/5] END C=0.1, degree=2, gamma=0.001, kernel=poly;, score=0.500 total time=  31.7s\n",
            "[CV 2/5] END C=0.1, degree=2, gamma=0.001, kernel=poly;, score=0.500 total time=  31.6s\n",
            "[CV 3/5] END C=0.1, degree=2, gamma=0.001, kernel=poly;, score=0.500 total time=  31.6s\n",
            "[CV 4/5] END C=0.1, degree=2, gamma=0.001, kernel=poly;, score=0.500 total time=  31.6s\n",
            "[CV 5/5] END C=0.1, degree=2, gamma=0.001, kernel=poly;, score=0.501 total time=  31.3s\n",
            "[CV 1/5] END C=0.1, degree=2, gamma=0.0001, kernel=poly;, score=0.500 total time=  31.8s\n",
            "[CV 2/5] END C=0.1, degree=2, gamma=0.0001, kernel=poly;, score=0.500 total time=  31.5s\n",
            "[CV 3/5] END C=0.1, degree=2, gamma=0.0001, kernel=poly;, score=0.500 total time=  31.3s\n",
            "[CV 4/5] END C=0.1, degree=2, gamma=0.0001, kernel=poly;, score=0.500 total time=  31.0s\n",
            "[CV 5/5] END C=0.1, degree=2, gamma=0.0001, kernel=poly;, score=0.501 total time=  31.5s\n",
            "[CV 1/5] END C=0.1, degree=3, gamma=1, kernel=poly;, score=0.979 total time=   2.0s\n",
            "[CV 2/5] END C=0.1, degree=3, gamma=1, kernel=poly;, score=0.980 total time=   2.0s\n",
            "[CV 3/5] END C=0.1, degree=3, gamma=1, kernel=poly;, score=0.982 total time=   2.1s\n",
            "[CV 4/5] END C=0.1, degree=3, gamma=1, kernel=poly;, score=0.980 total time=   2.0s\n",
            "[CV 5/5] END C=0.1, degree=3, gamma=1, kernel=poly;, score=0.981 total time=   2.0s\n",
            "[CV 1/5] END C=0.1, degree=3, gamma=0.1, kernel=poly;, score=0.963 total time=   9.9s\n",
            "[CV 2/5] END C=0.1, degree=3, gamma=0.1, kernel=poly;, score=0.963 total time=   9.9s\n",
            "[CV 3/5] END C=0.1, degree=3, gamma=0.1, kernel=poly;, score=0.967 total time=   9.9s\n",
            "[CV 4/5] END C=0.1, degree=3, gamma=0.1, kernel=poly;, score=0.963 total time=   9.9s\n",
            "[CV 5/5] END C=0.1, degree=3, gamma=0.1, kernel=poly;, score=0.966 total time=   9.9s\n",
            "[CV 1/5] END C=0.1, degree=3, gamma=0.01, kernel=poly;, score=0.500 total time=  31.1s\n",
            "[CV 2/5] END C=0.1, degree=3, gamma=0.01, kernel=poly;, score=0.500 total time=  31.4s\n",
            "[CV 3/5] END C=0.1, degree=3, gamma=0.01, kernel=poly;, score=0.500 total time=  32.4s\n",
            "[CV 4/5] END C=0.1, degree=3, gamma=0.01, kernel=poly;, score=0.500 total time=  31.8s\n",
            "[CV 5/5] END C=0.1, degree=3, gamma=0.01, kernel=poly;, score=0.501 total time=  31.2s\n",
            "[CV 1/5] END C=0.1, degree=3, gamma=0.001, kernel=poly;, score=0.500 total time=  31.3s\n",
            "[CV 2/5] END C=0.1, degree=3, gamma=0.001, kernel=poly;, score=0.500 total time=  32.7s\n",
            "[CV 3/5] END C=0.1, degree=3, gamma=0.001, kernel=poly;, score=0.500 total time=  32.9s\n",
            "[CV 4/5] END C=0.1, degree=3, gamma=0.001, kernel=poly;, score=0.500 total time=  31.5s\n",
            "[CV 5/5] END C=0.1, degree=3, gamma=0.001, kernel=poly;, score=0.501 total time=  31.0s\n",
            "[CV 1/5] END C=0.1, degree=3, gamma=0.0001, kernel=poly;, score=0.500 total time=  31.6s\n",
            "[CV 2/5] END C=0.1, degree=3, gamma=0.0001, kernel=poly;, score=0.500 total time=  31.5s\n",
            "[CV 3/5] END C=0.1, degree=3, gamma=0.0001, kernel=poly;, score=0.500 total time=  30.9s\n",
            "[CV 4/5] END C=0.1, degree=3, gamma=0.0001, kernel=poly;, score=0.500 total time=  31.3s\n",
            "[CV 5/5] END C=0.1, degree=3, gamma=0.0001, kernel=poly;, score=0.501 total time=  31.2s\n",
            "[CV 1/5] END C=1, degree=2, gamma=1, kernel=poly;, score=0.979 total time=   2.0s\n",
            "[CV 2/5] END C=1, degree=2, gamma=1, kernel=poly;, score=0.979 total time=   2.0s\n",
            "[CV 3/5] END C=1, degree=2, gamma=1, kernel=poly;, score=0.981 total time=   2.0s\n",
            "[CV 4/5] END C=1, degree=2, gamma=1, kernel=poly;, score=0.981 total time=   2.1s\n",
            "[CV 5/5] END C=1, degree=2, gamma=1, kernel=poly;, score=0.981 total time=   2.0s\n",
            "[CV 1/5] END C=1, degree=2, gamma=0.1, kernel=poly;, score=0.970 total time=   3.9s\n",
            "[CV 2/5] END C=1, degree=2, gamma=0.1, kernel=poly;, score=0.973 total time=   3.9s\n",
            "[CV 3/5] END C=1, degree=2, gamma=0.1, kernel=poly;, score=0.978 total time=   3.9s\n",
            "[CV 4/5] END C=1, degree=2, gamma=0.1, kernel=poly;, score=0.971 total time=   4.0s\n",
            "[CV 5/5] END C=1, degree=2, gamma=0.1, kernel=poly;, score=0.976 total time=   4.0s\n",
            "[CV 1/5] END C=1, degree=2, gamma=0.01, kernel=poly;, score=0.949 total time=  22.7s\n",
            "[CV 2/5] END C=1, degree=2, gamma=0.01, kernel=poly;, score=0.952 total time=  23.0s\n",
            "[CV 3/5] END C=1, degree=2, gamma=0.01, kernel=poly;, score=0.950 total time=  23.1s\n",
            "[CV 4/5] END C=1, degree=2, gamma=0.01, kernel=poly;, score=0.949 total time=  23.4s\n",
            "[CV 5/5] END C=1, degree=2, gamma=0.01, kernel=poly;, score=0.952 total time=  23.3s\n",
            "[CV 1/5] END C=1, degree=2, gamma=0.001, kernel=poly;, score=0.500 total time=  31.3s\n",
            "[CV 2/5] END C=1, degree=2, gamma=0.001, kernel=poly;, score=0.500 total time=  31.3s\n",
            "[CV 3/5] END C=1, degree=2, gamma=0.001, kernel=poly;, score=0.500 total time=  31.1s\n",
            "[CV 4/5] END C=1, degree=2, gamma=0.001, kernel=poly;, score=0.500 total time=  31.2s\n",
            "[CV 5/5] END C=1, degree=2, gamma=0.001, kernel=poly;, score=0.501 total time=  31.2s\n",
            "[CV 1/5] END C=1, degree=2, gamma=0.0001, kernel=poly;, score=0.500 total time=  31.0s\n",
            "[CV 2/5] END C=1, degree=2, gamma=0.0001, kernel=poly;, score=0.500 total time=  31.3s\n",
            "[CV 3/5] END C=1, degree=2, gamma=0.0001, kernel=poly;, score=0.500 total time=  31.3s\n",
            "[CV 4/5] END C=1, degree=2, gamma=0.0001, kernel=poly;, score=0.500 total time=  31.4s\n",
            "[CV 5/5] END C=1, degree=2, gamma=0.0001, kernel=poly;, score=0.501 total time=  31.3s\n",
            "[CV 1/5] END C=1, degree=3, gamma=1, kernel=poly;, score=0.979 total time=   2.1s\n",
            "[CV 2/5] END C=1, degree=3, gamma=1, kernel=poly;, score=0.977 total time=   2.1s\n",
            "[CV 3/5] END C=1, degree=3, gamma=1, kernel=poly;, score=0.981 total time=   2.2s\n",
            "[CV 4/5] END C=1, degree=3, gamma=1, kernel=poly;, score=0.979 total time=   2.2s\n",
            "[CV 5/5] END C=1, degree=3, gamma=1, kernel=poly;, score=0.977 total time=   2.1s\n",
            "[CV 1/5] END C=1, degree=3, gamma=0.1, kernel=poly;, score=0.969 total time=   4.4s\n",
            "[CV 2/5] END C=1, degree=3, gamma=0.1, kernel=poly;, score=0.971 total time=   4.4s\n",
            "[CV 3/5] END C=1, degree=3, gamma=0.1, kernel=poly;, score=0.975 total time=   4.5s\n",
            "[CV 4/5] END C=1, degree=3, gamma=0.1, kernel=poly;, score=0.969 total time=   4.4s\n",
            "[CV 5/5] END C=1, degree=3, gamma=0.1, kernel=poly;, score=0.975 total time=   4.4s\n",
            "[CV 1/5] END C=1, degree=3, gamma=0.01, kernel=poly;, score=0.500 total time=  31.1s\n",
            "[CV 2/5] END C=1, degree=3, gamma=0.01, kernel=poly;, score=0.500 total time=  31.4s\n",
            "[CV 3/5] END C=1, degree=3, gamma=0.01, kernel=poly;, score=0.500 total time=  31.2s\n",
            "[CV 4/5] END C=1, degree=3, gamma=0.01, kernel=poly;, score=0.500 total time=  31.5s\n",
            "[CV 5/5] END C=1, degree=3, gamma=0.01, kernel=poly;, score=0.501 total time=  31.0s\n",
            "[CV 1/5] END C=1, degree=3, gamma=0.001, kernel=poly;, score=0.500 total time=  31.2s\n",
            "[CV 2/5] END C=1, degree=3, gamma=0.001, kernel=poly;, score=0.500 total time=  31.4s\n",
            "[CV 3/5] END C=1, degree=3, gamma=0.001, kernel=poly;, score=0.500 total time=  31.2s\n",
            "[CV 4/5] END C=1, degree=3, gamma=0.001, kernel=poly;, score=0.500 total time=  31.4s\n",
            "[CV 5/5] END C=1, degree=3, gamma=0.001, kernel=poly;, score=0.501 total time=  31.2s\n",
            "[CV 1/5] END C=1, degree=3, gamma=0.0001, kernel=poly;, score=0.500 total time=  31.1s\n",
            "[CV 2/5] END C=1, degree=3, gamma=0.0001, kernel=poly;, score=0.500 total time=  31.2s\n",
            "[CV 3/5] END C=1, degree=3, gamma=0.0001, kernel=poly;, score=0.500 total time=  30.9s\n",
            "[CV 4/5] END C=1, degree=3, gamma=0.0001, kernel=poly;, score=0.500 total time=  31.2s\n",
            "[CV 5/5] END C=1, degree=3, gamma=0.0001, kernel=poly;, score=0.501 total time=  30.9s\n",
            "[CV 1/5] END C=10, degree=2, gamma=1, kernel=poly;, score=0.979 total time=   2.1s\n",
            "[CV 2/5] END C=10, degree=2, gamma=1, kernel=poly;, score=0.977 total time=   2.2s\n",
            "[CV 3/5] END C=10, degree=2, gamma=1, kernel=poly;, score=0.981 total time=   2.2s\n",
            "[CV 4/5] END C=10, degree=2, gamma=1, kernel=poly;, score=0.979 total time=   2.2s\n",
            "[CV 5/5] END C=10, degree=2, gamma=1, kernel=poly;, score=0.976 total time=   2.3s\n",
            "[CV 1/5] END C=10, degree=2, gamma=0.1, kernel=poly;, score=0.977 total time=   2.4s\n",
            "[CV 2/5] END C=10, degree=2, gamma=0.1, kernel=poly;, score=0.980 total time=   2.5s\n",
            "[CV 3/5] END C=10, degree=2, gamma=0.1, kernel=poly;, score=0.981 total time=   2.4s\n",
            "[CV 4/5] END C=10, degree=2, gamma=0.1, kernel=poly;, score=0.978 total time=   2.4s\n",
            "[CV 5/5] END C=10, degree=2, gamma=0.1, kernel=poly;, score=0.978 total time=   2.4s\n",
            "[CV 1/5] END C=10, degree=2, gamma=0.01, kernel=poly;, score=0.963 total time=   8.4s\n",
            "[CV 2/5] END C=10, degree=2, gamma=0.01, kernel=poly;, score=0.965 total time=   8.6s\n",
            "[CV 3/5] END C=10, degree=2, gamma=0.01, kernel=poly;, score=0.969 total time=   8.7s\n",
            "[CV 4/5] END C=10, degree=2, gamma=0.01, kernel=poly;, score=0.965 total time=   8.7s\n",
            "[CV 5/5] END C=10, degree=2, gamma=0.01, kernel=poly;, score=0.968 total time=   8.6s\n",
            "[CV 1/5] END C=10, degree=2, gamma=0.001, kernel=poly;, score=0.500 total time=  31.1s\n",
            "[CV 2/5] END C=10, degree=2, gamma=0.001, kernel=poly;, score=0.500 total time=  31.3s\n",
            "[CV 3/5] END C=10, degree=2, gamma=0.001, kernel=poly;, score=0.500 total time=  31.3s\n",
            "[CV 4/5] END C=10, degree=2, gamma=0.001, kernel=poly;, score=0.500 total time=  31.1s\n",
            "[CV 5/5] END C=10, degree=2, gamma=0.001, kernel=poly;, score=0.501 total time=  31.2s\n",
            "[CV 1/5] END C=10, degree=2, gamma=0.0001, kernel=poly;, score=0.500 total time=  31.3s\n",
            "[CV 2/5] END C=10, degree=2, gamma=0.0001, kernel=poly;, score=0.500 total time=  31.1s\n",
            "[CV 3/5] END C=10, degree=2, gamma=0.0001, kernel=poly;, score=0.500 total time=  31.2s\n",
            "[CV 4/5] END C=10, degree=2, gamma=0.0001, kernel=poly;, score=0.500 total time=  31.2s\n",
            "[CV 5/5] END C=10, degree=2, gamma=0.0001, kernel=poly;, score=0.501 total time=  31.4s\n",
            "[CV 1/5] END C=10, degree=3, gamma=1, kernel=poly;, score=0.976 total time=   3.1s\n",
            "[CV 2/5] END C=10, degree=3, gamma=1, kernel=poly;, score=0.973 total time=   3.1s\n",
            "[CV 3/5] END C=10, degree=3, gamma=1, kernel=poly;, score=0.978 total time=   3.2s\n",
            "[CV 4/5] END C=10, degree=3, gamma=1, kernel=poly;, score=0.976 total time=   3.0s\n",
            "[CV 5/5] END C=10, degree=3, gamma=1, kernel=poly;, score=0.970 total time=   3.0s\n",
            "[CV 1/5] END C=10, degree=3, gamma=0.1, kernel=poly;, score=0.975 total time=   2.6s\n",
            "[CV 2/5] END C=10, degree=3, gamma=0.1, kernel=poly;, score=0.979 total time=   2.6s\n",
            "[CV 3/5] END C=10, degree=3, gamma=0.1, kernel=poly;, score=0.980 total time=   2.6s\n",
            "[CV 4/5] END C=10, degree=3, gamma=0.1, kernel=poly;, score=0.976 total time=   2.6s\n",
            "[CV 5/5] END C=10, degree=3, gamma=0.1, kernel=poly;, score=0.979 total time=   2.7s\n",
            "[CV 1/5] END C=10, degree=3, gamma=0.01, kernel=poly;, score=0.948 total time=  27.6s\n",
            "[CV 2/5] END C=10, degree=3, gamma=0.01, kernel=poly;, score=0.954 total time=  27.8s\n",
            "[CV 3/5] END C=10, degree=3, gamma=0.01, kernel=poly;, score=0.953 total time=  27.6s\n",
            "[CV 4/5] END C=10, degree=3, gamma=0.01, kernel=poly;, score=0.954 total time=  27.9s\n",
            "[CV 5/5] END C=10, degree=3, gamma=0.01, kernel=poly;, score=0.956 total time=  27.8s\n",
            "[CV 1/5] END C=10, degree=3, gamma=0.001, kernel=poly;, score=0.500 total time=  31.8s\n",
            "[CV 2/5] END C=10, degree=3, gamma=0.001, kernel=poly;, score=0.500 total time=  32.5s\n",
            "[CV 3/5] END C=10, degree=3, gamma=0.001, kernel=poly;, score=0.500 total time=  31.4s\n",
            "[CV 4/5] END C=10, degree=3, gamma=0.001, kernel=poly;, score=0.500 total time=  31.5s\n",
            "[CV 5/5] END C=10, degree=3, gamma=0.001, kernel=poly;, score=0.501 total time=  31.0s\n",
            "[CV 1/5] END C=10, degree=3, gamma=0.0001, kernel=poly;, score=0.500 total time=  31.2s\n",
            "[CV 2/5] END C=10, degree=3, gamma=0.0001, kernel=poly;, score=0.500 total time=  31.2s\n",
            "[CV 3/5] END C=10, degree=3, gamma=0.0001, kernel=poly;, score=0.500 total time=  31.2s\n",
            "[CV 4/5] END C=10, degree=3, gamma=0.0001, kernel=poly;, score=0.500 total time=  31.4s\n",
            "[CV 5/5] END C=10, degree=3, gamma=0.0001, kernel=poly;, score=0.501 total time=  31.0s\n",
            "[CV 1/5] END C=100, degree=2, gamma=1, kernel=poly;, score=0.976 total time=   3.4s\n",
            "[CV 2/5] END C=100, degree=2, gamma=1, kernel=poly;, score=0.975 total time=   3.4s\n",
            "[CV 3/5] END C=100, degree=2, gamma=1, kernel=poly;, score=0.979 total time=   3.4s\n",
            "[CV 4/5] END C=100, degree=2, gamma=1, kernel=poly;, score=0.977 total time=   3.4s\n",
            "[CV 5/5] END C=100, degree=2, gamma=1, kernel=poly;, score=0.971 total time=   3.1s\n",
            "[CV 1/5] END C=100, degree=2, gamma=0.1, kernel=poly;, score=0.979 total time=   2.0s\n",
            "[CV 2/5] END C=100, degree=2, gamma=0.1, kernel=poly;, score=0.979 total time=   2.0s\n",
            "[CV 3/5] END C=100, degree=2, gamma=0.1, kernel=poly;, score=0.981 total time=   2.0s\n",
            "[CV 4/5] END C=100, degree=2, gamma=0.1, kernel=poly;, score=0.981 total time=   2.1s\n",
            "[CV 5/5] END C=100, degree=2, gamma=0.1, kernel=poly;, score=0.981 total time=   2.0s\n",
            "[CV 1/5] END C=100, degree=2, gamma=0.01, kernel=poly;, score=0.970 total time=   3.9s\n",
            "[CV 2/5] END C=100, degree=2, gamma=0.01, kernel=poly;, score=0.973 total time=   3.9s\n",
            "[CV 3/5] END C=100, degree=2, gamma=0.01, kernel=poly;, score=0.978 total time=   3.9s\n",
            "[CV 4/5] END C=100, degree=2, gamma=0.01, kernel=poly;, score=0.971 total time=   3.9s\n",
            "[CV 5/5] END C=100, degree=2, gamma=0.01, kernel=poly;, score=0.976 total time=   3.9s\n",
            "[CV 1/5] END C=100, degree=2, gamma=0.001, kernel=poly;, score=0.949 total time=  23.8s\n",
            "[CV 2/5] END C=100, degree=2, gamma=0.001, kernel=poly;, score=0.952 total time=  24.0s\n",
            "[CV 3/5] END C=100, degree=2, gamma=0.001, kernel=poly;, score=0.950 total time=  23.2s\n",
            "[CV 4/5] END C=100, degree=2, gamma=0.001, kernel=poly;, score=0.949 total time=  23.4s\n",
            "[CV 5/5] END C=100, degree=2, gamma=0.001, kernel=poly;, score=0.952 total time=  23.7s\n",
            "[CV 1/5] END C=100, degree=2, gamma=0.0001, kernel=poly;, score=0.500 total time=  31.5s\n",
            "[CV 2/5] END C=100, degree=2, gamma=0.0001, kernel=poly;, score=0.500 total time=  31.5s\n",
            "[CV 3/5] END C=100, degree=2, gamma=0.0001, kernel=poly;, score=0.500 total time=  33.2s\n",
            "[CV 4/5] END C=100, degree=2, gamma=0.0001, kernel=poly;, score=0.500 total time=  33.3s\n",
            "[CV 5/5] END C=100, degree=2, gamma=0.0001, kernel=poly;, score=0.501 total time=  33.3s\n",
            "[CV 1/5] END C=100, degree=3, gamma=1, kernel=poly;, score=0.975 total time=   3.6s\n",
            "[CV 2/5] END C=100, degree=3, gamma=1, kernel=poly;, score=0.970 total time=   3.6s\n",
            "[CV 3/5] END C=100, degree=3, gamma=1, kernel=poly;, score=0.973 total time=   3.6s\n",
            "[CV 4/5] END C=100, degree=3, gamma=1, kernel=poly;, score=0.973 total time=   3.4s\n",
            "[CV 5/5] END C=100, degree=3, gamma=1, kernel=poly;, score=0.968 total time=   3.4s\n",
            "[CV 1/5] END C=100, degree=3, gamma=0.1, kernel=poly;, score=0.979 total time=   2.1s\n",
            "[CV 2/5] END C=100, degree=3, gamma=0.1, kernel=poly;, score=0.980 total time=   2.1s\n",
            "[CV 3/5] END C=100, degree=3, gamma=0.1, kernel=poly;, score=0.982 total time=   2.1s\n",
            "[CV 4/5] END C=100, degree=3, gamma=0.1, kernel=poly;, score=0.980 total time=   2.1s\n",
            "[CV 5/5] END C=100, degree=3, gamma=0.1, kernel=poly;, score=0.981 total time=   2.2s\n",
            "[CV 1/5] END C=100, degree=3, gamma=0.01, kernel=poly;, score=0.963 total time=  10.4s\n",
            "[CV 2/5] END C=100, degree=3, gamma=0.01, kernel=poly;, score=0.963 total time=  10.5s\n",
            "[CV 3/5] END C=100, degree=3, gamma=0.01, kernel=poly;, score=0.967 total time=  10.4s\n",
            "[CV 4/5] END C=100, degree=3, gamma=0.01, kernel=poly;, score=0.963 total time=  10.5s\n",
            "[CV 5/5] END C=100, degree=3, gamma=0.01, kernel=poly;, score=0.966 total time=  10.5s\n",
            "[CV 1/5] END C=100, degree=3, gamma=0.001, kernel=poly;, score=0.500 total time=  33.4s\n",
            "[CV 2/5] END C=100, degree=3, gamma=0.001, kernel=poly;, score=0.500 total time=  33.2s\n",
            "[CV 3/5] END C=100, degree=3, gamma=0.001, kernel=poly;, score=0.500 total time=  33.2s\n",
            "[CV 4/5] END C=100, degree=3, gamma=0.001, kernel=poly;, score=0.500 total time=  33.3s\n",
            "[CV 5/5] END C=100, degree=3, gamma=0.001, kernel=poly;, score=0.501 total time=  33.3s\n",
            "[CV 1/5] END C=100, degree=3, gamma=0.0001, kernel=poly;, score=0.500 total time=  33.3s\n",
            "[CV 2/5] END C=100, degree=3, gamma=0.0001, kernel=poly;, score=0.500 total time=  33.0s\n",
            "[CV 3/5] END C=100, degree=3, gamma=0.0001, kernel=poly;, score=0.500 total time=  33.1s\n",
            "[CV 4/5] END C=100, degree=3, gamma=0.0001, kernel=poly;, score=0.500 total time=  33.5s\n",
            "[CV 5/5] END C=100, degree=3, gamma=0.0001, kernel=poly;, score=0.501 total time=  33.3s\n",
            "[CV 1/5] END C=1000, degree=2, gamma=1, kernel=poly;, score=0.972 total time=   4.3s\n",
            "[CV 2/5] END C=1000, degree=2, gamma=1, kernel=poly;, score=0.969 total time=   4.2s\n",
            "[CV 3/5] END C=1000, degree=2, gamma=1, kernel=poly;, score=0.971 total time=   4.1s\n",
            "[CV 4/5] END C=1000, degree=2, gamma=1, kernel=poly;, score=0.973 total time=   3.8s\n",
            "[CV 5/5] END C=1000, degree=2, gamma=1, kernel=poly;, score=0.968 total time=   3.7s\n",
            "[CV 1/5] END C=1000, degree=2, gamma=0.1, kernel=poly;, score=0.979 total time=   2.3s\n",
            "[CV 2/5] END C=1000, degree=2, gamma=0.1, kernel=poly;, score=0.977 total time=   2.3s\n",
            "[CV 3/5] END C=1000, degree=2, gamma=0.1, kernel=poly;, score=0.981 total time=   2.3s\n",
            "[CV 4/5] END C=1000, degree=2, gamma=0.1, kernel=poly;, score=0.979 total time=   2.3s\n",
            "[CV 5/5] END C=1000, degree=2, gamma=0.1, kernel=poly;, score=0.976 total time=   2.3s\n",
            "[CV 1/5] END C=1000, degree=2, gamma=0.01, kernel=poly;, score=0.977 total time=   2.6s\n",
            "[CV 2/5] END C=1000, degree=2, gamma=0.01, kernel=poly;, score=0.980 total time=   2.6s\n",
            "[CV 3/5] END C=1000, degree=2, gamma=0.01, kernel=poly;, score=0.981 total time=   2.6s\n",
            "[CV 4/5] END C=1000, degree=2, gamma=0.01, kernel=poly;, score=0.978 total time=   2.5s\n",
            "[CV 5/5] END C=1000, degree=2, gamma=0.01, kernel=poly;, score=0.978 total time=   2.5s\n",
            "[CV 1/5] END C=1000, degree=2, gamma=0.001, kernel=poly;, score=0.963 total time=   8.9s\n",
            "[CV 2/5] END C=1000, degree=2, gamma=0.001, kernel=poly;, score=0.965 total time=   9.1s\n",
            "[CV 3/5] END C=1000, degree=2, gamma=0.001, kernel=poly;, score=0.969 total time=   9.0s\n",
            "[CV 4/5] END C=1000, degree=2, gamma=0.001, kernel=poly;, score=0.965 total time=   9.0s\n",
            "[CV 5/5] END C=1000, degree=2, gamma=0.001, kernel=poly;, score=0.968 total time=   9.0s\n",
            "[CV 1/5] END C=1000, degree=2, gamma=0.0001, kernel=poly;, score=0.500 total time=  33.1s\n",
            "[CV 2/5] END C=1000, degree=2, gamma=0.0001, kernel=poly;, score=0.500 total time=  33.0s\n",
            "[CV 3/5] END C=1000, degree=2, gamma=0.0001, kernel=poly;, score=0.500 total time=  33.1s\n",
            "[CV 4/5] END C=1000, degree=2, gamma=0.0001, kernel=poly;, score=0.500 total time=  33.2s\n",
            "[CV 5/5] END C=1000, degree=2, gamma=0.0001, kernel=poly;, score=0.501 total time=  33.3s\n",
            "[CV 1/5] END C=1000, degree=3, gamma=1, kernel=poly;, score=0.975 total time=   3.6s\n",
            "[CV 2/5] END C=1000, degree=3, gamma=1, kernel=poly;, score=0.970 total time=   3.6s\n",
            "[CV 3/5] END C=1000, degree=3, gamma=1, kernel=poly;, score=0.973 total time=   3.6s\n",
            "[CV 4/5] END C=1000, degree=3, gamma=1, kernel=poly;, score=0.973 total time=   3.4s\n",
            "[CV 5/5] END C=1000, degree=3, gamma=1, kernel=poly;, score=0.968 total time=   3.5s\n",
            "[CV 1/5] END C=1000, degree=3, gamma=0.1, kernel=poly;, score=0.979 total time=   2.3s\n",
            "[CV 2/5] END C=1000, degree=3, gamma=0.1, kernel=poly;, score=0.977 total time=   2.2s\n",
            "[CV 3/5] END C=1000, degree=3, gamma=0.1, kernel=poly;, score=0.981 total time=   2.3s\n",
            "[CV 4/5] END C=1000, degree=3, gamma=0.1, kernel=poly;, score=0.979 total time=   2.3s\n",
            "[CV 5/5] END C=1000, degree=3, gamma=0.1, kernel=poly;, score=0.977 total time=   2.2s\n",
            "[CV 1/5] END C=1000, degree=3, gamma=0.01, kernel=poly;, score=0.969 total time=   4.6s\n",
            "[CV 2/5] END C=1000, degree=3, gamma=0.01, kernel=poly;, score=0.971 total time=   4.6s\n",
            "[CV 3/5] END C=1000, degree=3, gamma=0.01, kernel=poly;, score=0.975 total time=   4.7s\n",
            "[CV 4/5] END C=1000, degree=3, gamma=0.01, kernel=poly;, score=0.969 total time=   4.6s\n",
            "[CV 5/5] END C=1000, degree=3, gamma=0.01, kernel=poly;, score=0.975 total time=   4.7s\n",
            "[CV 1/5] END C=1000, degree=3, gamma=0.001, kernel=poly;, score=0.500 total time=  33.2s\n",
            "[CV 2/5] END C=1000, degree=3, gamma=0.001, kernel=poly;, score=0.500 total time=  33.3s\n",
            "[CV 3/5] END C=1000, degree=3, gamma=0.001, kernel=poly;, score=0.500 total time=  33.1s\n",
            "[CV 4/5] END C=1000, degree=3, gamma=0.001, kernel=poly;, score=0.500 total time=  33.3s\n",
            "[CV 5/5] END C=1000, degree=3, gamma=0.001, kernel=poly;, score=0.501 total time=  33.0s\n",
            "[CV 1/5] END C=1000, degree=3, gamma=0.0001, kernel=poly;, score=0.500 total time=  33.2s\n",
            "[CV 2/5] END C=1000, degree=3, gamma=0.0001, kernel=poly;, score=0.500 total time=  33.2s\n",
            "[CV 3/5] END C=1000, degree=3, gamma=0.0001, kernel=poly;, score=0.500 total time=  33.2s\n",
            "[CV 4/5] END C=1000, degree=3, gamma=0.0001, kernel=poly;, score=0.500 total time=  33.2s\n",
            "[CV 5/5] END C=1000, degree=3, gamma=0.0001, kernel=poly;, score=0.501 total time=  33.2s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(estimator=SVC(),\n",
              "             param_grid={'C': [0.1, 1, 10, 100, 1000], 'degree': [2, 3],\n",
              "                         'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
              "                         'kernel': ['poly']},\n",
              "             verbose=3)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print best parameter after tuning\n",
        "print(grid.best_params_)\n",
        "  \n",
        "# print how our model looks after hyper-parameter tuning\n",
        "print(grid.best_estimator_)"
      ],
      "metadata": {
        "id": "j7MKkKYV5yB0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7f3fd2e-7a25-4d67-8479-013a6c86fa7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'C': 0.1, 'degree': 3, 'gamma': 1, 'kernel': 'poly'}\n",
            "SVC(C=0.1, gamma=1, kernel='poly')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m1 = SVC(random_state=0,kernel='linear',degree=3, class_weight='balanced', max_iter=20000, C=0.1,gamma=1).fit(tEmb, tYX.Y)  # SVC is ok to use. See updated Rules.=\n",
        "m1.score(tEmb, tYX.Y)   # in-sample accuracy"
      ],
      "metadata": {
        "id": "9KfSLElKv2nm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "846673cf-2e98-4c60-fd88-f935a4f5ad22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9829"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m.score(vEmb1[:10000], tYX.Y)"
      ],
      "metadata": {
        "id": "1MN42uKotW25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "70c4ca1e-2638-4982-de4e-604483aa9ea5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-99-e0a1d005c3d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvEmb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtYX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    649\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"multilabel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \"\"\"\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    332\u001b[0m         raise ValueError(\n\u001b[1;32m    333\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m         )\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [10000, 20000]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m1.score(vEmb[:10000], tYX.Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEtMrmV42fXc",
        "outputId": "4ca2e553-de39-4165-93b9-cae370220e7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4985"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1PsK7LZJIgQ"
      },
      "source": [
        "pY = pd.DataFrame(m.predict(vEmb1), index=vX.index, columns=['y'])   # predicted targets\n",
        "ToCSV((pY>0.5)*1, 'MySubmission')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **References:**"
      ],
      "metadata": {
        "id": "pzBsjCvS_kEw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Remember to cite your sources here as well! At the least, your textbook should be cited. Google Scholar allows you to effortlessly copy/paste an APA citation format for books and publications. Also cite StackOverflow, package documentation, and other meaningful internet resources to help your peers learn from these (and to avoid plagiarism claims)."
      ],
      "metadata": {
        "id": "2kr8Q-9T_nAb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font size=5>‚åõ</font> <strong><font color=orange size=5>Do not exceed competition's runtime limit!</font></strong>\n",
        "\n",
        "<hr color=red>\n"
      ],
      "metadata": {
        "id": "DoF2GoB_QGw9"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nosV1OWFJPx5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b0fa085-4016-4a9d-dde5-39849d1a84d9"
      },
      "source": [
        "tmr.ShowTime()    # measure Colab's runtime. Do not remove. Keep as the last cell in your notebook."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Runtime is 204 sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udpl5HJ4JSLr"
      },
      "source": [
        "# üí°**Starter Ideas**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWllDRgiJVDJ"
      },
      "source": [
        "1. Learn about DNA [&#127910;](https://www.youtube.com/results?search_query=nucleotides+genes+amino+acids+)\n",
        "1. Try a larger training sample. \n",
        "1. Try longer training DNA strings, but SBERT may have a cap on string length, so you might split DNA into several strings and then concatenate or average resulting vectors\n",
        "1. Try other pretrained SBERT models. Note that DNA sequence uses ACGT letters, but many other models were trained on multilingual text. So, you might prefer those that were trained on mostly ASCII.\n",
        "1. SBERT is trained on word tokens (typically, separated by spaces), but DNA sequence has no spaces. Try placing spaces after every character or some semantically meaningful subsequences (this might require more domain knowledge).\n",
        "1. Try Google's [USE](https://tfhub.dev/google/universal-sentence-encoder-multilingual/3) embedding models\n",
        "1. Try Facebook's [LASER](https://github.com/facebookresearch/LASER) and [others](https://tfhub.dev/s?module-type=text-language-model). \n",
        "1. Try [Enformer](https://tfhub.dev/deepmind/enformer/1) for gene expressions. See [DeepMind paper](https://deepmind.com/blog/article/enformer).\n",
        "1. Try building your own embeddings on the given sequences. SBERT and other packages make it easy (just a few lines), but it may take too much time.\n",
        "1. Assess distribution of character patterns (single, doubles, triplets, ...). For example, an ACGT string generates AC, CG, GT doubles and ACG and CGT triplets. Does one class have more subsequences of some type? This might be a feature in your model. \n",
        "1. Try features built as counts of subsequences (singles, doubles, triplets, ...). Consider EDA first.\n",
        "1. Concatenate or otherwise combine multiple embeddings derived from each gene string\n",
        "1. Learn from [*The genetic code*](https://www.khanacademy.org/science/ap-biology/gene-expression-and-regulation/translation/a/the-genetic-code-discovery-and-properties), Khan Academy.\n",
        "1. Learn from [*Apply Machine Learning Algorithms for Genomics Data Classification*](https://medium.com/mlearning-ai/apply-machine-learning-algorithms-for-genomics-data-classification-132972933723)\n",
        "1. Learn from [*Efficient counting of k-mers in DNA sequences using a bloom filter*](https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-12-333) P√°ll Melsted et al. 2011\n",
        "1. Try [Byte Pair Encoding](https://www.derczynski.com/papers/archive/BPE_Gage.pdf) and [SentencePiece](https://arxiv.org/pdf/1808.06226.pdf) to auto identification of \"important\" [k-mers](https://en.wikipedia.org/wiki/K-mer) (substrings)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFwKcfCnmmGh"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}